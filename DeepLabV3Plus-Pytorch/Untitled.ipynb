{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bb487-ec76-41a3-b97a-05ecf2bf7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "/home/irfan/Desktop/Data/VOCtrainval_11-May-2012/VOCdevkit/VOC2012\n",
      "/home/irfan/Desktop/Data/VOCtrainval_11-May-2012/VOCdevkit/VOC2012\n",
      "Dataset: voc, Train set: 1464, Val set: 1449\n",
      "[!] Retrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Itrs 10/30000, Loss=2.205890\n",
      "Epoch 1, Itrs 20/30000, Loss=1.901858\n",
      "Epoch 1, Itrs 30/30000, Loss=1.520020\n",
      "Epoch 1, Itrs 40/30000, Loss=1.275033\n",
      "Epoch 1, Itrs 50/30000, Loss=1.144743\n",
      "Epoch 1, Itrs 60/30000, Loss=1.173431\n",
      "Epoch 1, Itrs 70/30000, Loss=1.187438\n",
      "Epoch 1, Itrs 80/30000, Loss=0.969259\n",
      "Epoch 1, Itrs 90/30000, Loss=1.068519\n",
      "Epoch 1, Itrs 100/30000, Loss=1.045613\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:29, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.786099\n",
      "Mean Acc: 0.323944\n",
      "FreqW Acc: 0.671203\n",
      "Mean IoU: 0.220988\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 1, Itrs 110/30000, Loss=0.977696\n",
      "Epoch 1, Itrs 120/30000, Loss=1.062680\n",
      "Epoch 1, Itrs 130/30000, Loss=0.945614\n",
      "Epoch 1, Itrs 140/30000, Loss=1.160699\n",
      "Epoch 1, Itrs 150/30000, Loss=1.070337\n",
      "Epoch 1, Itrs 160/30000, Loss=1.160323\n",
      "Epoch 1, Itrs 170/30000, Loss=0.955402\n",
      "Epoch 1, Itrs 180/30000, Loss=0.969656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Itrs 190/30000, Loss=1.011022\n",
      "Epoch 2, Itrs 200/30000, Loss=0.829223\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:31, 46.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.817726\n",
      "Mean Acc: 0.365300\n",
      "FreqW Acc: 0.691617\n",
      "Mean IoU: 0.292977\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 2, Itrs 210/30000, Loss=0.722534\n",
      "Epoch 2, Itrs 220/30000, Loss=1.125346\n",
      "Epoch 2, Itrs 230/30000, Loss=0.754738\n",
      "Epoch 2, Itrs 240/30000, Loss=0.733517\n",
      "Epoch 2, Itrs 250/30000, Loss=0.764044\n",
      "Epoch 2, Itrs 260/30000, Loss=0.868816\n",
      "Epoch 2, Itrs 270/30000, Loss=0.788485\n",
      "Epoch 2, Itrs 280/30000, Loss=0.799486\n",
      "Epoch 2, Itrs 290/30000, Loss=0.851149\n",
      "Epoch 2, Itrs 300/30000, Loss=0.672945\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:34, 41.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.826052\n",
      "Mean Acc: 0.502019\n",
      "FreqW Acc: 0.727499\n",
      "Mean IoU: 0.370697\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 2, Itrs 310/30000, Loss=0.518520\n",
      "Epoch 2, Itrs 320/30000, Loss=0.711163\n",
      "Epoch 2, Itrs 330/30000, Loss=0.859526\n",
      "Epoch 2, Itrs 340/30000, Loss=0.741890\n",
      "Epoch 2, Itrs 350/30000, Loss=0.747536\n",
      "Epoch 2, Itrs 360/30000, Loss=1.043136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Itrs 370/30000, Loss=0.699834\n",
      "Epoch 3, Itrs 380/30000, Loss=0.769415\n",
      "Epoch 3, Itrs 390/30000, Loss=0.759056\n",
      "Epoch 3, Itrs 400/30000, Loss=1.035663\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:37, 38.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.811057\n",
      "Mean Acc: 0.517459\n",
      "FreqW Acc: 0.716631\n",
      "Mean IoU: 0.377250\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 3, Itrs 410/30000, Loss=0.727359\n",
      "Epoch 3, Itrs 420/30000, Loss=0.656133\n",
      "Epoch 3, Itrs 430/30000, Loss=0.603982\n",
      "Epoch 3, Itrs 440/30000, Loss=0.745984\n",
      "Epoch 3, Itrs 450/30000, Loss=0.772483\n",
      "Epoch 3, Itrs 460/30000, Loss=0.541606\n",
      "Epoch 3, Itrs 470/30000, Loss=0.772766\n",
      "Epoch 3, Itrs 480/30000, Loss=0.909828\n",
      "Epoch 3, Itrs 490/30000, Loss=0.711780\n",
      "Epoch 3, Itrs 500/30000, Loss=0.833714\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:40, 35.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.842804\n",
      "Mean Acc: 0.617007\n",
      "FreqW Acc: 0.748221\n",
      "Mean IoU: 0.439266\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 3, Itrs 510/30000, Loss=0.866564\n",
      "Epoch 3, Itrs 520/30000, Loss=0.782183\n",
      "Epoch 3, Itrs 530/30000, Loss=0.745726\n",
      "Epoch 3, Itrs 540/30000, Loss=0.951090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Itrs 550/30000, Loss=0.669846\n",
      "Epoch 4, Itrs 560/30000, Loss=0.807388\n",
      "Epoch 4, Itrs 570/30000, Loss=0.610103\n",
      "Epoch 4, Itrs 580/30000, Loss=0.586290\n",
      "Epoch 4, Itrs 590/30000, Loss=0.744392\n",
      "Epoch 4, Itrs 600/30000, Loss=0.657794\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:40, 35.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.811919\n",
      "Mean Acc: 0.548697\n",
      "FreqW Acc: 0.714365\n",
      "Mean IoU: 0.374630\n",
      "\n",
      "Epoch 4, Itrs 610/30000, Loss=0.698302\n",
      "Epoch 4, Itrs 620/30000, Loss=0.667098\n",
      "Epoch 4, Itrs 630/30000, Loss=0.614721\n",
      "Epoch 4, Itrs 640/30000, Loss=0.701381\n",
      "Epoch 4, Itrs 650/30000, Loss=0.604944\n",
      "Epoch 4, Itrs 660/30000, Loss=0.801547\n",
      "Epoch 4, Itrs 670/30000, Loss=0.669645\n",
      "Epoch 4, Itrs 680/30000, Loss=0.808866\n",
      "Epoch 4, Itrs 690/30000, Loss=0.670116\n",
      "Epoch 4, Itrs 700/30000, Loss=0.605156\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:42, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.855026\n",
      "Mean Acc: 0.571194\n",
      "FreqW Acc: 0.760225\n",
      "Mean IoU: 0.443090\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 4, Itrs 710/30000, Loss=0.698868\n",
      "Epoch 4, Itrs 720/30000, Loss=0.630628\n",
      "Epoch 4, Itrs 730/30000, Loss=0.605239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Itrs 740/30000, Loss=0.782815\n",
      "Epoch 5, Itrs 750/30000, Loss=0.674828\n",
      "Epoch 5, Itrs 760/30000, Loss=0.493697\n",
      "Epoch 5, Itrs 770/30000, Loss=0.849630\n",
      "Epoch 5, Itrs 780/30000, Loss=0.663116\n",
      "Epoch 5, Itrs 790/30000, Loss=0.712633\n",
      "Epoch 5, Itrs 800/30000, Loss=0.851721\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:43, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.851521\n",
      "Mean Acc: 0.582852\n",
      "FreqW Acc: 0.759173\n",
      "Mean IoU: 0.447581\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 5, Itrs 810/30000, Loss=0.600734\n",
      "Epoch 5, Itrs 820/30000, Loss=0.700676\n",
      "Epoch 5, Itrs 830/30000, Loss=0.627909\n",
      "Epoch 5, Itrs 840/30000, Loss=0.630524\n",
      "Epoch 5, Itrs 850/30000, Loss=0.702301\n",
      "Epoch 5, Itrs 860/30000, Loss=0.661575\n",
      "Epoch 5, Itrs 870/30000, Loss=0.659091\n",
      "Epoch 5, Itrs 880/30000, Loss=0.526040\n",
      "Epoch 5, Itrs 890/30000, Loss=0.530235\n",
      "Epoch 5, Itrs 900/30000, Loss=0.642625\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:43, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.867046\n",
      "Mean Acc: 0.558128\n",
      "FreqW Acc: 0.771137\n",
      "Mean IoU: 0.458508\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 5, Itrs 910/30000, Loss=0.675064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Itrs 920/30000, Loss=0.581226\n",
      "Epoch 6, Itrs 930/30000, Loss=0.573403\n",
      "Epoch 6, Itrs 940/30000, Loss=0.597094\n",
      "Epoch 6, Itrs 950/30000, Loss=0.580692\n",
      "Epoch 6, Itrs 960/30000, Loss=0.756777\n",
      "Epoch 6, Itrs 970/30000, Loss=0.521757\n",
      "Epoch 6, Itrs 980/30000, Loss=0.656100\n",
      "Epoch 6, Itrs 990/30000, Loss=0.551606\n",
      "Epoch 6, Itrs 1000/30000, Loss=0.531019\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [01:03, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.857354\n",
      "Mean Acc: 0.631673\n",
      "FreqW Acc: 0.766960\n",
      "Mean IoU: 0.469954\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 6, Itrs 1010/30000, Loss=0.506697\n",
      "Epoch 6, Itrs 1020/30000, Loss=0.669812\n",
      "Epoch 6, Itrs 1030/30000, Loss=0.650483\n",
      "Epoch 6, Itrs 1040/30000, Loss=0.562851\n",
      "Epoch 6, Itrs 1050/30000, Loss=0.551657\n",
      "Epoch 6, Itrs 1060/30000, Loss=0.611441\n",
      "Epoch 6, Itrs 1070/30000, Loss=0.560746\n",
      "Epoch 6, Itrs 1080/30000, Loss=0.730659\n",
      "Epoch 6, Itrs 1090/30000, Loss=0.738057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Itrs 1100/30000, Loss=0.618939\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [01:11, 20.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.862507\n",
      "Mean Acc: 0.568721\n",
      "FreqW Acc: 0.766608\n",
      "Mean IoU: 0.460668\n",
      "\n",
      "Epoch 7, Itrs 1110/30000, Loss=0.506326\n",
      "Epoch 7, Itrs 1120/30000, Loss=0.578314\n",
      "Epoch 7, Itrs 1130/30000, Loss=0.646819\n",
      "Epoch 7, Itrs 1140/30000, Loss=0.600567\n",
      "Epoch 7, Itrs 1150/30000, Loss=0.602498\n",
      "Epoch 7, Itrs 1160/30000, Loss=0.482231\n",
      "Epoch 7, Itrs 1170/30000, Loss=0.581169\n",
      "Epoch 7, Itrs 1180/30000, Loss=0.653244\n",
      "Epoch 7, Itrs 1190/30000, Loss=0.627210\n",
      "Epoch 7, Itrs 1200/30000, Loss=0.615032\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [01:05, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.863275\n",
      "Mean Acc: 0.609404\n",
      "FreqW Acc: 0.771082\n",
      "Mean IoU: 0.478638\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 7, Itrs 1210/30000, Loss=0.561607\n",
      "Epoch 7, Itrs 1220/30000, Loss=0.539837\n",
      "Epoch 7, Itrs 1230/30000, Loss=0.488799\n",
      "Epoch 7, Itrs 1240/30000, Loss=0.484606\n",
      "Epoch 7, Itrs 1250/30000, Loss=0.482505\n",
      "Epoch 7, Itrs 1260/30000, Loss=0.545888\n",
      "Epoch 7, Itrs 1270/30000, Loss=0.504692\n",
      "Epoch 7, Itrs 1280/30000, Loss=0.606648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Itrs 1290/30000, Loss=0.548875\n",
      "Epoch 8, Itrs 1300/30000, Loss=0.691866\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [01:07, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.819686\n",
      "Mean Acc: 0.694521\n",
      "FreqW Acc: 0.738408\n",
      "Mean IoU: 0.484381\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 8, Itrs 1310/30000, Loss=0.499462\n",
      "Epoch 8, Itrs 1320/30000, Loss=0.552982\n",
      "Epoch 8, Itrs 1330/30000, Loss=0.568633\n",
      "Epoch 8, Itrs 1340/30000, Loss=0.465694\n",
      "Epoch 8, Itrs 1350/30000, Loss=0.631194\n",
      "Epoch 8, Itrs 1360/30000, Loss=0.569666\n",
      "Epoch 8, Itrs 1370/30000, Loss=0.794282\n",
      "Epoch 8, Itrs 1380/30000, Loss=0.572162\n",
      "Epoch 8, Itrs 1390/30000, Loss=0.710181\n",
      "Epoch 8, Itrs 1400/30000, Loss=0.686522\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [01:07, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.861794\n",
      "Mean Acc: 0.672313\n",
      "FreqW Acc: 0.776862\n",
      "Mean IoU: 0.503302\n",
      "\n",
      "Model saved as checkpoints/best_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "Epoch 8, Itrs 1410/30000, Loss=0.625048\n",
      "Epoch 8, Itrs 1420/30000, Loss=0.394901\n",
      "Epoch 8, Itrs 1430/30000, Loss=0.674403\n",
      "Epoch 8, Itrs 1440/30000, Loss=0.584236\n",
      "Epoch 8, Itrs 1450/30000, Loss=0.609418\n",
      "Epoch 8, Itrs 1460/30000, Loss=0.519667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/irfan/Desktop/Code/Linux-IO/python_38/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Itrs 1470/30000, Loss=0.634790\n",
      "Epoch 9, Itrs 1480/30000, Loss=0.525040\n",
      "Epoch 9, Itrs 1490/30000, Loss=0.496918\n",
      "Epoch 9, Itrs 1500/30000, Loss=0.513684\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1449it [00:43, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acc: 0.868722\n",
      "Mean Acc: 0.581371\n",
      "FreqW Acc: 0.775994\n",
      "Mean IoU: 0.484661\n",
      "\n",
      "Epoch 9, Itrs 1510/30000, Loss=0.428949\n",
      "Epoch 9, Itrs 1520/30000, Loss=0.347959\n",
      "Epoch 9, Itrs 1530/30000, Loss=0.580871\n",
      "Epoch 9, Itrs 1540/30000, Loss=0.374853\n",
      "Epoch 9, Itrs 1550/30000, Loss=0.473576\n",
      "Epoch 9, Itrs 1560/30000, Loss=0.660444\n",
      "Epoch 9, Itrs 1570/30000, Loss=0.616421\n",
      "Epoch 9, Itrs 1580/30000, Loss=0.469424\n",
      "Epoch 9, Itrs 1590/30000, Loss=0.569541\n",
      "Epoch 9, Itrs 1600/30000, Loss=0.639958\n",
      "Model saved as checkpoints/latest_deeplabv3plus_mobilenet_voc_os16.pth\n",
      "validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1317it [00:41, 30.48it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import network\n",
    "import utils\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "from datasets import VOCSegmentation, Cityscapes\n",
    "from utils import ext_transforms as et\n",
    "from metrics import StreamSegMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.visualizer import Visualizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='max_split_size_mb:4096'\n",
    "\n",
    "def get_argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Datset Options\n",
    "    parser.add_argument(\"--data_root\", type=str, default='./datasets/data',\n",
    "                        help=\"path to Dataset\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default='voc',\n",
    "                        choices=['voc', 'cityscapes'], help='Name of dataset')\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=None,\n",
    "                        help=\"num classes (default: None)\")\n",
    "\n",
    "    # Deeplab Options\n",
    "    available_models = sorted(name for name in network.modeling.__dict__ if name.islower() and \\\n",
    "                              not (name.startswith(\"__\") or name.startswith('_')) and callable(\n",
    "                              network.modeling.__dict__[name])\n",
    "                              )\n",
    "    parser.add_argument(\"--model\", type=str, default='deeplabv3plus_mobilenet',\n",
    "                        choices=available_models, help='model name')\n",
    "    parser.add_argument(\"--separable_conv\", action='store_true', default=False,\n",
    "                        help=\"apply separable conv to decoder and aspp\")\n",
    "    parser.add_argument(\"--output_stride\", type=int, default=16, choices=[8, 16])\n",
    "\n",
    "    # Train Options\n",
    "    parser.add_argument(\"--test_only\", action='store_true', default=False)\n",
    "    parser.add_argument(\"--save_val_results\", action='store_true', default=False,\n",
    "                        help=\"save segmentation results to \\\"./results\\\"\")\n",
    "    parser.add_argument(\"--total_itrs\", type=int, default=30e3,\n",
    "                        help=\"epoch number (default: 30k)\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01,\n",
    "                        help=\"learning rate (default: 0.01)\")\n",
    "    parser.add_argument(\"--lr_policy\", type=str, default='poly', choices=['poly', 'step'],\n",
    "                        help=\"learning rate scheduler policy\")\n",
    "    parser.add_argument(\"--step_size\", type=int, default=10000)\n",
    "    parser.add_argument(\"--crop_val\", action='store_true', default=False,\n",
    "                        help='crop validation (default: False)')\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16,\n",
    "                        help='batch size (default: 16)')\n",
    "    parser.add_argument(\"--val_batch_size\", type=int, default=4,\n",
    "                        help='batch size for validation (default: 4)')\n",
    "    parser.add_argument(\"--crop_size\", type=int, default=513)\n",
    "\n",
    "    parser.add_argument(\"--ckpt\", default=None, type=str,\n",
    "                        help=\"restore from checkpoint\")\n",
    "    parser.add_argument(\"--continue_training\", action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument(\"--loss_type\", type=str, default='cross_entropy',\n",
    "                        choices=['cross_entropy', 'focal_loss'], help=\"loss type (default: False)\")\n",
    "    parser.add_argument(\"--gpu_id\", type=str, default='0',\n",
    "                        help=\"GPU ID\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-4,\n",
    "                        help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=1,\n",
    "                        help=\"random seed (default: 1)\")\n",
    "    parser.add_argument(\"--print_interval\", type=int, default=10,\n",
    "                        help=\"print interval of loss (default: 10)\")\n",
    "    parser.add_argument(\"--val_interval\", type=int, default=100,\n",
    "                        help=\"epoch interval for eval (default: 100)\")\n",
    "    parser.add_argument(\"--download\", action='store_true', default=False,\n",
    "                        help=\"download datasets\")\n",
    "\n",
    "    # PASCAL VOC Options\n",
    "    parser.add_argument(\"--year\", type=str, default='2012',\n",
    "                        choices=['2012_aug', '2012', '2011', '2009', '2008', '2007'], help='year of VOC')\n",
    "\n",
    "    # Visdom options\n",
    "    parser.add_argument(\"--enable_vis\", action='store_true', default=False,\n",
    "                        help=\"use visdom for visualization\")\n",
    "    parser.add_argument(\"--vis_port\", type=str, default='13570',\n",
    "                        help='port for visdom')\n",
    "    parser.add_argument(\"--vis_env\", type=str, default='main',\n",
    "                        help='env for visdom')\n",
    "    parser.add_argument(\"--vis_num_samples\", type=int, default=8,\n",
    "                        help='number of samples for visualization (default: 8)')\n",
    "    return parser\n",
    "\n",
    "\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        # Datset Options\n",
    "        self.data_root ='/home/irfan/Desktop/Data/VOCtrainval_11-May-2012'#VOCdevkit/VOC2012/'                  \n",
    "        self.dataset ='voc'\n",
    "        self.num_classes =None\n",
    "\n",
    "        # Deeplab Options\n",
    "        available_models = sorted(name for name in network.modeling.__dict__ if name.islower() and \\\n",
    "                                  not (name.startswith(\"__\") or name.startswith('_')) and callable(\n",
    "                                  network.modeling.__dict__[name])\n",
    "                                  )\n",
    "        self.model = 'deeplabv3plus_mobilenet'\n",
    "        self.separable_conv = False\n",
    "        self.output_stride  = 16\n",
    "        # Train Options\n",
    "        self.test_only      = False\n",
    "        self.save_val_results = False\n",
    "        self.total_itrs     = 30e3\n",
    "        self.lr             = 0.01\n",
    "        self.lr_policy      = 'poly'\n",
    "\n",
    "        self.step_size      = 10000\n",
    "        self.crop_val       = False\n",
    "        self.batch_size     = 8\n",
    "        self.val_batch_size = 2\n",
    "        self.crop_size      = 256\n",
    "        self.ckpt           = None\n",
    "        self.continue_training = False\n",
    "\n",
    "        self.loss_type      = 'cross_entropy'\n",
    "        self.gpu_id         = '0'\n",
    "        self.weight_decay   = 1e-4\n",
    "        self.random_seed    = 1\n",
    "        self.print_interval = 10\n",
    "        self.val_interval   = 100\n",
    "        self.download       = False\n",
    "        # PASCAL VOC Options\n",
    "        self.year           ='2012'\n",
    "\n",
    "        # Visdom options\n",
    "        self.enable_vis     = False              \n",
    "        self.vis_port       ='13570'\n",
    "        self.vis_env        ='main'\n",
    "        self.vis_num_samples =8\n",
    "        \n",
    "def get_dataset(opts):\n",
    "    \"\"\" Dataset And Augmentation\n",
    "    \"\"\"\n",
    "    if opts.dataset == 'voc':\n",
    "        train_transform = et.ExtCompose([\n",
    "            # et.ExtResize(size=opts.crop_size),\n",
    "            et.ExtRandomScale((0.5, 2.0)),\n",
    "            et.ExtRandomCrop(size=(opts.crop_size, opts.crop_size), pad_if_needed=True),\n",
    "            et.ExtRandomHorizontalFlip(),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        if opts.crop_val:\n",
    "            val_transform = et.ExtCompose([\n",
    "                et.ExtResize(opts.crop_size),\n",
    "                et.ExtCenterCrop(opts.crop_size),\n",
    "                et.ExtToTensor(),\n",
    "                et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            val_transform = et.ExtCompose([\n",
    "                et.ExtToTensor(),\n",
    "                et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        train_dst = VOCSegmentation(root=opts.data_root, year=opts.year,\n",
    "                                    image_set='train', download=opts.download, transform=train_transform)\n",
    "        val_dst = VOCSegmentation(root=opts.data_root, year=opts.year,\n",
    "                                  image_set='val', download=False, transform=val_transform)\n",
    "\n",
    "    if opts.dataset == 'cityscapes':\n",
    "        train_transform = et.ExtCompose([\n",
    "            # et.ExtResize( 512 ),\n",
    "            et.ExtRandomCrop(size=(opts.crop_size, opts.crop_size)),\n",
    "            et.ExtColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "            et.ExtRandomHorizontalFlip(),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        val_transform = et.ExtCompose([\n",
    "            # et.ExtResize( 512 ),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        train_dst = Cityscapes(root=opts.data_root,\n",
    "                               split='train', transform=train_transform)\n",
    "        val_dst = Cityscapes(root=opts.data_root,\n",
    "                             split='val', transform=val_transform)\n",
    "    return train_dst, val_dst\n",
    "\n",
    "\n",
    "def validate(opts, model, loader, device, metrics, ret_samples_ids=None):\n",
    "    \"\"\"Do validation and return specified samples\"\"\"\n",
    "    metrics.reset()\n",
    "    ret_samples = []\n",
    "    if opts.save_val_results:\n",
    "        if not os.path.exists('results'):\n",
    "            os.mkdir('results')\n",
    "        denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "        img_id = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in tqdm(enumerate(loader)):\n",
    "\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = outputs.detach().max(dim=1)[1].cpu().numpy()\n",
    "            targets = labels.cpu().numpy()\n",
    "\n",
    "            metrics.update(targets, preds)\n",
    "            if ret_samples_ids is not None and i in ret_samples_ids:  # get vis samples\n",
    "                ret_samples.append(\n",
    "                    (images[0].detach().cpu().numpy(), targets[0], preds[0]))\n",
    "\n",
    "            if opts.save_val_results:\n",
    "                for i in range(len(images)):\n",
    "                    image = images[i].detach().cpu().numpy()\n",
    "                    target = targets[i]\n",
    "                    pred = preds[i]\n",
    "\n",
    "                    image = (denorm(image) * 255).transpose(1, 2, 0).astype(np.uint8)\n",
    "                    target = loader.dataset.decode_target(target).astype(np.uint8)\n",
    "                    pred = loader.dataset.decode_target(pred).astype(np.uint8)\n",
    "\n",
    "                    Image.fromarray(image).save('results/%d_image.png' % img_id)\n",
    "                    Image.fromarray(target).save('results/%d_target.png' % img_id)\n",
    "                    Image.fromarray(pred).save('results/%d_pred.png' % img_id)\n",
    "\n",
    "                    fig = plt.figure()\n",
    "                    plt.imshow(image)\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(pred, alpha=0.7)\n",
    "                    ax = plt.gca()\n",
    "                    ax.xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "                    ax.yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "                    plt.savefig('results/%d_overlay.png' % img_id, bbox_inches='tight', pad_inches=0)\n",
    "                    plt.close()\n",
    "                    img_id += 1\n",
    "\n",
    "        score = metrics.get_results()\n",
    "    return score, ret_samples\n",
    "\n",
    "\n",
    "def main(opts):\n",
    "    #opts = get_argparser().parse_args()\n",
    "    if opts.dataset.lower() == 'voc':\n",
    "        opts.num_classes = 21\n",
    "    elif opts.dataset.lower() == 'cityscapes':\n",
    "        opts.num_classes = 19\n",
    "\n",
    "    # Setup visualization\n",
    "    vis = Visualizer(port=opts.vis_port,\n",
    "                     env=opts.vis_env) if opts.enable_vis else None\n",
    "    if vis is not None:  # display options\n",
    "        vis.vis_table(\"Options\", vars(opts))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opts.gpu_id\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device: %s\" % device)\n",
    "\n",
    "    # Setup random seed\n",
    "    torch.manual_seed(opts.random_seed)\n",
    "    np.random.seed(opts.random_seed)\n",
    "    random.seed(opts.random_seed)\n",
    "\n",
    "    # Setup dataloader\n",
    "    if opts.dataset == 'voc' and not opts.crop_val:\n",
    "        opts.val_batch_size = 1\n",
    "\n",
    "    train_dst, val_dst = get_dataset(opts)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dst, batch_size=opts.batch_size, shuffle=True, num_workers=2,\n",
    "        drop_last=True)  # drop_last=True to ignore single-image batches.\n",
    "    val_loader = data.DataLoader(\n",
    "        val_dst, batch_size=opts.val_batch_size, shuffle=True, num_workers=2)\n",
    "    print(\"Dataset: %s, Train set: %d, Val set: %d\" %\n",
    "          (opts.dataset, len(train_dst), len(val_dst)))\n",
    "\n",
    "    # Set up model (all models are 'constructed at network.modeling)\n",
    "    model = network.modeling.__dict__[opts.model](num_classes=opts.num_classes, output_stride=opts.output_stride)\n",
    "    if opts.separable_conv and 'plus' in opts.model:\n",
    "        network.convert_to_separable_conv(model.classifier)\n",
    "    utils.set_bn_momentum(model.backbone, momentum=0.01)\n",
    "\n",
    "    # Set up metrics\n",
    "    metrics = StreamSegMetrics(opts.num_classes)\n",
    "\n",
    "    # Set up optimizer\n",
    "    optimizer = torch.optim.SGD(params=[\n",
    "        {'params': model.backbone.parameters(), 'lr': 0.1 * opts.lr},\n",
    "        {'params': model.classifier.parameters(), 'lr': opts.lr},\n",
    "    ], lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)\n",
    "    # optimizer = torch.optim.SGD(params=model.parameters(), lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)\n",
    "    # torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.lr_decay_step, gamma=opts.lr_decay_factor)\n",
    "    if opts.lr_policy == 'poly':\n",
    "        scheduler = utils.PolyLR(optimizer, opts.total_itrs, power=0.9)\n",
    "    elif opts.lr_policy == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.step_size, gamma=0.1)\n",
    "\n",
    "    # Set up criterion\n",
    "    # criterion = utils.get_loss(opts.loss_type)\n",
    "    if opts.loss_type == 'focal_loss':\n",
    "        criterion = utils.FocalLoss(ignore_index=255, size_average=True)\n",
    "    elif opts.loss_type == 'cross_entropy':\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=255, reduction='mean')\n",
    "\n",
    "    def save_ckpt(path):\n",
    "        \"\"\" save current model\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            \"cur_itrs\": cur_itrs,\n",
    "            \"model_state\": model.module.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict(),\n",
    "            \"best_score\": best_score,\n",
    "        }, path)\n",
    "        print(\"Model saved as %s\" % path)\n",
    "\n",
    "    utils.mkdir('checkpoints')\n",
    "    # Restore\n",
    "    best_score = 0.0\n",
    "    cur_itrs = 0\n",
    "    cur_epochs = 0\n",
    "    if opts.ckpt is not None and os.path.isfile(opts.ckpt):\n",
    "        # https://github.com/VainF/DeepLabV3Plus-Pytorch/issues/8#issuecomment-605601402, @PytaichukBohdan\n",
    "        checkpoint = torch.load(opts.ckpt, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        if opts.continue_training:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "            cur_itrs = checkpoint[\"cur_itrs\"]\n",
    "            best_score = checkpoint['best_score']\n",
    "            print(\"Training state restored from %s\" % opts.ckpt)\n",
    "        print(\"Model restored from %s\" % opts.ckpt)\n",
    "        del checkpoint  # free memory\n",
    "    else:\n",
    "        print(\"[!] Retrain\")\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "\n",
    "    # ==========   Train Loop   ==========#\n",
    "    vis_sample_id = np.random.randint(0, len(val_loader), opts.vis_num_samples,\n",
    "                                      np.int32) if opts.enable_vis else None  # sample idxs for visualization\n",
    "    denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # denormalization for ori images\n",
    "\n",
    "    if opts.test_only:\n",
    "        model.eval()\n",
    "        val_score, ret_samples = validate(\n",
    "            opts=opts, model=model, loader=val_loader, device=device, metrics=metrics, ret_samples_ids=vis_sample_id)\n",
    "        print(metrics.to_str(val_score))\n",
    "        return\n",
    "\n",
    "    interval_loss = 0\n",
    "    while True:  # cur_itrs < opts.total_itrs:\n",
    "        # =====  Train  =====\n",
    "        model.train()\n",
    "        cur_epochs += 1\n",
    "        for (images, labels) in train_loader:\n",
    "            cur_itrs += 1\n",
    "\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            np_loss = loss.detach().cpu().numpy()\n",
    "            interval_loss += np_loss\n",
    "            if vis is not None:\n",
    "                vis.vis_scalar('Loss', cur_itrs, np_loss)\n",
    "\n",
    "            if (cur_itrs) % 10 == 0:\n",
    "                interval_loss = interval_loss / 10\n",
    "                print(\"Epoch %d, Itrs %d/%d, Loss=%f\" %\n",
    "                      (cur_epochs, cur_itrs, opts.total_itrs, interval_loss))\n",
    "                interval_loss = 0.0\n",
    "\n",
    "            if (cur_itrs) % opts.val_interval == 0:\n",
    "                save_ckpt('checkpoints/latest_%s_%s_os%d.pth' %\n",
    "                          (opts.model, opts.dataset, opts.output_stride))\n",
    "                print(\"validation...\")\n",
    "                model.eval()\n",
    "                val_score, ret_samples = validate(\n",
    "                    opts=opts, model=model, loader=val_loader, device=device, metrics=metrics,\n",
    "                    ret_samples_ids=vis_sample_id)\n",
    "                print(metrics.to_str(val_score))\n",
    "                if val_score['Mean IoU'] > best_score:  # save best model\n",
    "                    best_score = val_score['Mean IoU']\n",
    "                    save_ckpt('checkpoints/best_%s_%s_os%d.pth' %\n",
    "                              (opts.model, opts.dataset, opts.output_stride))\n",
    "\n",
    "                if vis is not None:  # visualize validation score and samples\n",
    "                    vis.vis_scalar(\"[Val] Overall Acc\", cur_itrs, val_score['Overall Acc'])\n",
    "                    vis.vis_scalar(\"[Val] Mean IoU\", cur_itrs, val_score['Mean IoU'])\n",
    "                    vis.vis_table(\"[Val] Class IoU\", val_score['Class IoU'])\n",
    "\n",
    "                    for k, (img, target, lbl) in enumerate(ret_samples):\n",
    "                        img = (denorm(img) * 255).astype(np.uint8)\n",
    "                        target = train_dst.decode_target(target).transpose(2, 0, 1).astype(np.uint8)\n",
    "                        lbl = train_dst.decode_target(lbl).transpose(2, 0, 1).astype(np.uint8)\n",
    "                        concat_img = np.concatenate((img, target, lbl), axis=2)  # concat along width\n",
    "                        vis.vis_image('Sample %d' % k, concat_img)\n",
    "                model.train()\n",
    "            scheduler.step()\n",
    "\n",
    "            if cur_itrs >= opts.total_itrs:\n",
    "                return\n",
    "\n",
    "#torch.cuda.memory._record_memory_history()\n",
    "params = Params()\n",
    "main(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5320e58e-a496-4874-8d19-3eb7c124b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7273bb-7618-4508-b7b5-8f404ab811cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_38",
   "language": "python",
   "name": "python_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
