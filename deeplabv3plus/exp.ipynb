{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9e300-5648-440d-8c19-4d440049fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import network\n",
    "import utils\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "from datasets import VOCSegmentation, Cityscapes\n",
    "from utils import ext_transforms as et\n",
    "from metrics import StreamSegMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.visualizer import Visualizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Datset Options\n",
    "    parser.add_argument(\"--data_root\", type=str, default='./datasets/data',\n",
    "                        help=\"path to Dataset\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default='voc',\n",
    "                        choices=['voc', 'cityscapes'], help='Name of dataset')\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=None,\n",
    "                        help=\"num classes (default: None)\")\n",
    "\n",
    "    # Deeplab Options\n",
    "    available_models = sorted(name for name in network.modeling.__dict__ if name.islower() and \\\n",
    "                              not (name.startswith(\"__\") or name.startswith('_')) and callable(\n",
    "                              network.modeling.__dict__[name])\n",
    "                              )\n",
    "    parser.add_argument(\"--model\", type=str, default='deeplabv3plus_mobilenet',\n",
    "                        choices=available_models, help='model name')\n",
    "    parser.add_argument(\"--separable_conv\", action='store_true', default=False,\n",
    "                        help=\"apply separable conv to decoder and aspp\")\n",
    "    parser.add_argument(\"--output_stride\", type=int, default=16, choices=[8, 16])\n",
    "\n",
    "    # Train Options\n",
    "    parser.add_argument(\"--test_only\", action='store_true', default=False)\n",
    "    parser.add_argument(\"--save_val_results\", action='store_true', default=False,\n",
    "                        help=\"save segmentation results to \\\"./results\\\"\")\n",
    "    parser.add_argument(\"--total_itrs\", type=int, default=30e3,\n",
    "                        help=\"epoch number (default: 30k)\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01,\n",
    "                        help=\"learning rate (default: 0.01)\")\n",
    "    parser.add_argument(\"--lr_policy\", type=str, default='poly', choices=['poly', 'step'],\n",
    "                        help=\"learning rate scheduler policy\")\n",
    "    parser.add_argument(\"--step_size\", type=int, default=10000)\n",
    "    parser.add_argument(\"--crop_val\", action='store_true', default=False,\n",
    "                        help='crop validation (default: False)')\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16,\n",
    "                        help='batch size (default: 16)')\n",
    "    parser.add_argument(\"--val_batch_size\", type=int, default=4,\n",
    "                        help='batch size for validation (default: 4)')\n",
    "    parser.add_argument(\"--crop_size\", type=int, default=513)\n",
    "\n",
    "    parser.add_argument(\"--ckpt\", default=None, type=str,\n",
    "                        help=\"restore from checkpoint\")\n",
    "    parser.add_argument(\"--continue_training\", action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument(\"--loss_type\", type=str, default='cross_entropy',\n",
    "                        choices=['cross_entropy', 'focal_loss'], help=\"loss type (default: False)\")\n",
    "    parser.add_argument(\"--gpu_id\", type=str, default='0',\n",
    "                        help=\"GPU ID\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-4,\n",
    "                        help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=1,\n",
    "                        help=\"random seed (default: 1)\")\n",
    "    parser.add_argument(\"--print_interval\", type=int, default=10,\n",
    "                        help=\"print interval of loss (default: 10)\")\n",
    "    parser.add_argument(\"--val_interval\", type=int, default=100,\n",
    "                        help=\"epoch interval for eval (default: 100)\")\n",
    "    parser.add_argument(\"--download\", action='store_true', default=False,\n",
    "                        help=\"download datasets\")\n",
    "\n",
    "    # PASCAL VOC Options\n",
    "    parser.add_argument(\"--year\", type=str, default='2012',\n",
    "                        choices=['2012_aug', '2012', '2011', '2009', '2008', '2007'], help='year of VOC')\n",
    "\n",
    "    # Visdom options\n",
    "    parser.add_argument(\"--enable_vis\", action='store_true', default=False,\n",
    "                        help=\"use visdom for visualization\")\n",
    "    parser.add_argument(\"--vis_port\", type=str, default='13570',\n",
    "                        help='port for visdom')\n",
    "    parser.add_argument(\"--vis_env\", type=str, default='main',\n",
    "                        help='env for visdom')\n",
    "    parser.add_argument(\"--vis_num_samples\", type=int, default=8,\n",
    "                        help='number of samples for visualization (default: 8)')\n",
    "    return parser\n",
    "\n",
    "\n",
    "def get_dataset(opts):\n",
    "    \"\"\" Dataset And Augmentation\n",
    "    \"\"\"\n",
    "    if opts.dataset == 'voc':\n",
    "        train_transform = et.ExtCompose([\n",
    "            # et.ExtResize(size=opts.crop_size),\n",
    "            et.ExtRandomScale((0.5, 2.0)),\n",
    "            et.ExtRandomCrop(size=(opts.crop_size, opts.crop_size), pad_if_needed=True),\n",
    "            et.ExtRandomHorizontalFlip(),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        if opts.crop_val:\n",
    "            val_transform = et.ExtCompose([\n",
    "                et.ExtResize(opts.crop_size),\n",
    "                et.ExtCenterCrop(opts.crop_size),\n",
    "                et.ExtToTensor(),\n",
    "                et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            val_transform = et.ExtCompose([\n",
    "                et.ExtToTensor(),\n",
    "                et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        train_dst = VOCSegmentation(root=opts.data_root, year=opts.year,\n",
    "                                    image_set='train', download=opts.download, transform=train_transform)\n",
    "        val_dst = VOCSegmentation(root=opts.data_root, year=opts.year,\n",
    "                                  image_set='val', download=False, transform=val_transform)\n",
    "\n",
    "    if opts.dataset == 'cityscapes':\n",
    "        train_transform = et.ExtCompose([\n",
    "            # et.ExtResize( 512 ),\n",
    "            et.ExtRandomCrop(size=(opts.crop_size, opts.crop_size)),\n",
    "            et.ExtColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "            et.ExtRandomHorizontalFlip(),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        val_transform = et.ExtCompose([\n",
    "            # et.ExtResize( 512 ),\n",
    "            et.ExtToTensor(),\n",
    "            et.ExtNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        train_dst = Cityscapes(root=opts.data_root,\n",
    "                               split='train', transform=train_transform)\n",
    "        val_dst = Cityscapes(root=opts.data_root,\n",
    "                             split='val', transform=val_transform)\n",
    "    return train_dst, val_dst\n",
    "\n",
    "\n",
    "def validate(opts, model, loader, device, metrics, ret_samples_ids=None):\n",
    "    \"\"\"Do validation and return specified samples\"\"\"\n",
    "    metrics.reset()\n",
    "    ret_samples = []\n",
    "    if opts.save_val_results:\n",
    "        if not os.path.exists('results'):\n",
    "            os.mkdir('results')\n",
    "        denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "        img_id = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in tqdm(enumerate(loader)):\n",
    "\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = outputs.detach().max(dim=1)[1].cpu().numpy()\n",
    "            targets = labels.cpu().numpy()\n",
    "\n",
    "            metrics.update(targets, preds)\n",
    "            if ret_samples_ids is not None and i in ret_samples_ids:  # get vis samples\n",
    "                ret_samples.append(\n",
    "                    (images[0].detach().cpu().numpy(), targets[0], preds[0]))\n",
    "\n",
    "            if opts.save_val_results:\n",
    "                for i in range(len(images)):\n",
    "                    image = images[i].detach().cpu().numpy()\n",
    "                    target = targets[i]\n",
    "                    pred = preds[i]\n",
    "\n",
    "                    image = (denorm(image) * 255).transpose(1, 2, 0).astype(np.uint8)\n",
    "                    target = loader.dataset.decode_target(target).astype(np.uint8)\n",
    "                    pred = loader.dataset.decode_target(pred).astype(np.uint8)\n",
    "\n",
    "                    Image.fromarray(image).save('results/%d_image.png' % img_id)\n",
    "                    Image.fromarray(target).save('results/%d_target.png' % img_id)\n",
    "                    Image.fromarray(pred).save('results/%d_pred.png' % img_id)\n",
    "\n",
    "                    fig = plt.figure()\n",
    "                    plt.imshow(image)\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(pred, alpha=0.7)\n",
    "                    ax = plt.gca()\n",
    "                    ax.xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "                    ax.yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "                    plt.savefig('results/%d_overlay.png' % img_id, bbox_inches='tight', pad_inches=0)\n",
    "                    plt.close()\n",
    "                    img_id += 1\n",
    "\n",
    "        score = metrics.get_results()\n",
    "    return score, ret_samples\n",
    "\n",
    "\n",
    "def main():\n",
    "    opts = get_argparser().parse_args()\n",
    "    if opts.dataset.lower() == 'voc':\n",
    "        opts.num_classes = 21\n",
    "    elif opts.dataset.lower() == 'cityscapes':\n",
    "        opts.num_classes = 19\n",
    "\n",
    "    # Setup visualization\n",
    "    vis = Visualizer(port=opts.vis_port,\n",
    "                     env=opts.vis_env) if opts.enable_vis else None\n",
    "    if vis is not None:  # display options\n",
    "        vis.vis_table(\"Options\", vars(opts))\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = opts.gpu_id\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device: %s\" % device)\n",
    "\n",
    "    # Setup random seed\n",
    "    torch.manual_seed(opts.random_seed)\n",
    "    np.random.seed(opts.random_seed)\n",
    "    random.seed(opts.random_seed)\n",
    "\n",
    "    # Setup dataloader\n",
    "    if opts.dataset == 'voc' and not opts.crop_val:\n",
    "        opts.val_batch_size = 1\n",
    "\n",
    "    train_dst, val_dst = get_dataset(opts)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dst, batch_size=opts.batch_size, shuffle=True, num_workers=2,\n",
    "        drop_last=True)  # drop_last=True to ignore single-image batches.\n",
    "    val_loader = data.DataLoader(\n",
    "        val_dst, batch_size=opts.val_batch_size, shuffle=True, num_workers=2)\n",
    "    print(\"Dataset: %s, Train set: %d, Val set: %d\" %\n",
    "          (opts.dataset, len(train_dst), len(val_dst)))\n",
    "\n",
    "    # Set up model (all models are 'constructed at network.modeling)\n",
    "    model = network.modeling.__dict__[opts.model](num_classes=opts.num_classes, output_stride=opts.output_stride)\n",
    "    if opts.separable_conv and 'plus' in opts.model:\n",
    "        network.convert_to_separable_conv(model.classifier)\n",
    "    utils.set_bn_momentum(model.backbone, momentum=0.01)\n",
    "\n",
    "    # Set up metrics\n",
    "    metrics = StreamSegMetrics(opts.num_classes)\n",
    "\n",
    "    # Set up optimizer\n",
    "    optimizer = torch.optim.SGD(params=[\n",
    "        {'params': model.backbone.parameters(), 'lr': 0.1 * opts.lr},\n",
    "        {'params': model.classifier.parameters(), 'lr': opts.lr},\n",
    "    ], lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)\n",
    "    # optimizer = torch.optim.SGD(params=model.parameters(), lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)\n",
    "    # torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.lr_decay_step, gamma=opts.lr_decay_factor)\n",
    "    if opts.lr_policy == 'poly':\n",
    "        scheduler = utils.PolyLR(optimizer, opts.total_itrs, power=0.9)\n",
    "    elif opts.lr_policy == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.step_size, gamma=0.1)\n",
    "\n",
    "    # Set up criterion\n",
    "    # criterion = utils.get_loss(opts.loss_type)\n",
    "    if opts.loss_type == 'focal_loss':\n",
    "        criterion = utils.FocalLoss(ignore_index=255, size_average=True)\n",
    "    elif opts.loss_type == 'cross_entropy':\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=255, reduction='mean')\n",
    "\n",
    "    def save_ckpt(path):\n",
    "        \"\"\" save current model\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            \"cur_itrs\": cur_itrs,\n",
    "            \"model_state\": model.module.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict(),\n",
    "            \"best_score\": best_score,\n",
    "        }, path)\n",
    "        print(\"Model saved as %s\" % path)\n",
    "\n",
    "    utils.mkdir('checkpoints')\n",
    "    # Restore\n",
    "    best_score = 0.0\n",
    "    cur_itrs = 0\n",
    "    cur_epochs = 0\n",
    "    if opts.ckpt is not None and os.path.isfile(opts.ckpt):\n",
    "        # https://github.com/VainF/DeepLabV3Plus-Pytorch/issues/8#issuecomment-605601402, @PytaichukBohdan\n",
    "        checkpoint = torch.load(opts.ckpt, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        if opts.continue_training:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "            cur_itrs = checkpoint[\"cur_itrs\"]\n",
    "            best_score = checkpoint['best_score']\n",
    "            print(\"Training state restored from %s\" % opts.ckpt)\n",
    "        print(\"Model restored from %s\" % opts.ckpt)\n",
    "        del checkpoint  # free memory\n",
    "    else:\n",
    "        print(\"[!] Retrain\")\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "\n",
    "    # ==========   Train Loop   ==========#\n",
    "    vis_sample_id = np.random.randint(0, len(val_loader), opts.vis_num_samples,\n",
    "                                      np.int32) if opts.enable_vis else None  # sample idxs for visualization\n",
    "    denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # denormalization for ori images\n",
    "\n",
    "    if opts.test_only:\n",
    "        model.eval()\n",
    "        val_score, ret_samples = validate(\n",
    "            opts=opts, model=model, loader=val_loader, device=device, metrics=metrics, ret_samples_ids=vis_sample_id)\n",
    "        print(metrics.to_str(val_score))\n",
    "        return\n",
    "\n",
    "    interval_loss = 0\n",
    "    while True:  # cur_itrs < opts.total_itrs:\n",
    "        # =====  Train  =====\n",
    "        model.train()\n",
    "        cur_epochs += 1\n",
    "        for (images, labels) in train_loader:\n",
    "            cur_itrs += 1\n",
    "\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            np_loss = loss.detach().cpu().numpy()\n",
    "            interval_loss += np_loss\n",
    "            if vis is not None:\n",
    "                vis.vis_scalar('Loss', cur_itrs, np_loss)\n",
    "\n",
    "            if (cur_itrs) % 10 == 0:\n",
    "                interval_loss = interval_loss / 10\n",
    "                print(\"Epoch %d, Itrs %d/%d, Loss=%f\" %\n",
    "                      (cur_epochs, cur_itrs, opts.total_itrs, interval_loss))\n",
    "                interval_loss = 0.0\n",
    "\n",
    "            if (cur_itrs) % opts.val_interval == 0:\n",
    "                save_ckpt('checkpoints/latest_%s_%s_os%d.pth' %\n",
    "                          (opts.model, opts.dataset, opts.output_stride))\n",
    "                print(\"validation...\")\n",
    "                model.eval()\n",
    "                val_score, ret_samples = validate(\n",
    "                    opts=opts, model=model, loader=val_loader, device=device, metrics=metrics,\n",
    "                    ret_samples_ids=vis_sample_id)\n",
    "                print(metrics.to_str(val_score))\n",
    "                if val_score['Mean IoU'] > best_score:  # save best model\n",
    "                    best_score = val_score['Mean IoU']\n",
    "                    save_ckpt('checkpoints/best_%s_%s_os%d.pth' %\n",
    "                              (opts.model, opts.dataset, opts.output_stride))\n",
    "\n",
    "                if vis is not None:  # visualize validation score and samples\n",
    "                    vis.vis_scalar(\"[Val] Overall Acc\", cur_itrs, val_score['Overall Acc'])\n",
    "                    vis.vis_scalar(\"[Val] Mean IoU\", cur_itrs, val_score['Mean IoU'])\n",
    "                    vis.vis_table(\"[Val] Class IoU\", val_score['Class IoU'])\n",
    "\n",
    "                    for k, (img, target, lbl) in enumerate(ret_samples):\n",
    "                        img = (denorm(img) * 255).astype(np.uint8)\n",
    "                        target = train_dst.decode_target(target).transpose(2, 0, 1).astype(np.uint8)\n",
    "                        lbl = train_dst.decode_target(lbl).transpose(2, 0, 1).astype(np.uint8)\n",
    "                        concat_img = np.concatenate((img, target, lbl), axis=2)  # concat along width\n",
    "                        vis.vis_image('Sample %d' % k, concat_img)\n",
    "                model.train()\n",
    "            scheduler.step()\n",
    "\n",
    "            if cur_itrs >= opts.total_itrs:\n",
    "                return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_38",
   "language": "python",
   "name": "python_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
