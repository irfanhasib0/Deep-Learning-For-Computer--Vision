{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea6d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29/04/2022\n",
    "#================================================================\n",
    "# Yolo V-3 by irfanhasib.me@gmail.com\n",
    "# Inspired by -\n",
    "# GitHub      : https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3\n",
    "#================================================================\n",
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Process, Queue, Pipe\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm,trange\n",
    "import pickle\n",
    "import zlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7ee22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 03:32:46.214678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-27 03:32:47.061820: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-27 03:32:47.065130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-27 03:32:47.086712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.086816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2022-05-27 03:32:47.086832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-27 03:32:47.095374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-27 03:32:47.095415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-27 03:32:47.097664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-27 03:32:47.099117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-27 03:32:47.099978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-27 03:32:47.101585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-27 03:32:47.101778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-27 03:32:47.101843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.101973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.102050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from yolo.model import YoloModel, calc_yolo_loss, calc_seg_loss\n",
    "from yolo.decoder import YoloDecodeNetout\n",
    "from yolo.dataset import Dataset\n",
    "from yolo.eval import get_mAP\n",
    "from yolo.utils import Utils\n",
    "from yolo.seg_loader import Seg_Utils\n",
    "from yolo.config import *\n",
    "from yolo.tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0627c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_test = False\n",
    "yolo_eval = False\n",
    "seg_test  = False\n",
    "sanity_check = False\n",
    "data_gen  = DATA_GEN\n",
    "debug     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8997dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                          : 2022-05-27 03:32:47.556272\n",
      "RAW_DATA_DIR                  : /home/irfan/Desktop/Code/Datasets/\n",
      "DATA_DIR                      : /home/irfan/Desktop/Data/\n",
      "TRAIN_CHECKPOINTS_FOLDER      : logs/exp-MNET_V2_224_V32_MUL_QL7_0003_EXP_107\n",
      "YOLO_TYPE                     : yolov3\n",
      "YOLO_MODEL                    : mobilenet\n",
      "YOLO_MODEL_LOAD_WTS           : model_data/mobilenet_v2_1.0_224_mod.h5\n",
      "YOLO_FRAMEWORK                : tf\n",
      "YOLO_V3_WEIGHTS               : model_data/yolov3.weights\n",
      "YOLO_V4_WEIGHTS               : model_data/yolov4.weights\n",
      "YOLO_V3_TINY_WEIGHTS          : model_data/yolov3-tiny.weights\n",
      "YOLO_V4_TINY_WEIGHTS          : model_data/yolov4-tiny.weights\n",
      "YOLO_TRT_QUANTIZE_MODE        : INT8\n",
      "YOLO_CUSTOM_WEIGHTS           : True\n",
      "YOLO_COCO_CLASSES             : model_data/coco/coco.names\n",
      "YOLO_STRIDES                  : [16, 32, 64]\n",
      "YOLO_ANCHOR_PER_SCALE         : 3\n",
      "YOLO_MAX_BBOX_PER_SCALE       : 100\n",
      "YOLO_INPUT_SIZE               : 224\n",
      "ANCHORS                       : [[[10, 14], [23, 27], [37, 58]], [[81, 82], [135, 169], [344, 319]], [[0, 0], [0, 0], [0, 0]]]\n",
      "SEED                          : 0\n",
      "DATA_GEN                      : False\n",
      "NO_OF_GRID                    : 2\n",
      "TRAIN_MODEL_SCALE             : 1\n",
      "TRAIN_SAVE_BEST_ONLY          : True\n",
      "TRAIN_SAVE_WEIGHTS_EVERY      : 1\n",
      "TRAIN_CLASSES                 : model_data/coco/coco.names\n",
      "TRAIN_ANNOT_PATH              : /home/irfan/Desktop/Data/COCO/annotations_trainval2017/annotations/instances_train2017.txt\n",
      "TRAIN_DATA_SAVE_PATH          : /home/irfan/Desktop/Data/COCO/train/\n",
      "TRAIN_IMG_PATH                : /home/irfan/Desktop/Code/Datasets/COCO/train2017/\n",
      "TRAIN_LOGDIR                  : log\n",
      "TRAIN_MODEL_PATH              : logs/exp-Disc103/model_epoch_10_val_det_loss_30.6821/weights\n",
      "TRAIN_LOAD_IMAGES_TO_RAM      : False\n",
      "TRAIN_BATCH_SIZE              : 64\n",
      "TRAIN_MINI_BATCH_SIZE         : 8\n",
      "TRAIN_LR                      : 0.0003\n",
      "TRAIN_INPUT_SIZE              : 224\n",
      "TRAIN_DATA_AUG                : False\n",
      "TRAIN_TRANSFER                : True\n",
      "TRAIN_FROM_CHECKPOINT         : False\n",
      "TRAIN_LR_INIT                 : 0.0001\n",
      "TRAIN_LR_END                  : 1e-06\n",
      "TRAIN_WARM_UP_EPOCHS          : 0\n",
      "TRAIN_EPOCHS                  : 20\n",
      "TRAIN_FREEZE_EPOCH            : 3\n",
      "TRAIN_SAVE_THR_SIZE           : 300\n",
      "TRAIN_HRES_INPUT_SIZE         : 224\n",
      "TRAIN_LRES_PRE_WTS            : \n",
      "TRAIN_USE_SE_LAYERS           : [0, 0, 0, 0, 0, 0]\n",
      "TRAIN_USE_DST                 : False\n",
      "TRAIN_USE_SEG                 : False\n",
      "TRAIN_LOSS_WTS                : [1.0, 0.0, 0.0]\n",
      "TRAIN_SEG_BG                  : True\n",
      "TRAIN_SEG_SCALE               : 2\n",
      "TRAIN_SEG_SUP_CAT             : False\n",
      "LOSS_XYWH_MSE                 : False\n",
      "LOSS_XYWH_IOU                 : True\n",
      "LOSS_IOU_TYPE                 : ciou\n",
      "LOSS_USE_FOCAL                : True\n",
      "LOSS_GRID_CORR                : True\n",
      "LOSS_WH_POW                   : 0\n",
      "LOSS_FILTER_BG_MASK           : True\n",
      "LOSS_BG_IOU_THRESH            : 0.5\n",
      "LOSS_WTS_BBOX                 : [1.0, 1.0, 1.0]\n",
      "MTL_USE_METHOD                : default\n",
      "MTL_NO_OF_BLOCKS              : 1\n",
      "MTL_CALC_GRAD_VAR             : False\n",
      "MTL_USE_MUL_PROB              : True\n",
      "MTL_USE_IND_PROB              : False\n",
      "MTL_USE_SIG_PROB              : False\n",
      "MTL_USE_COMB_PROB             : False\n",
      "MTL_USE_ALPHA                 : 0.0\n",
      "MTL_GRADS_QLEN                : 7\n",
      "MTL_LOSS_WTS                  : [1.0, 1.0, 0.5]\n",
      "TEST_ANNOT_PATH               : /home/irfan/Desktop/Data/COCO/annotations_trainval2017/annotations/instances_val2017.txt\n",
      "TEST_DATA_SAVE_PATH           : /home/irfan/Desktop/Data/COCO/test/\n",
      "TEST_IMG_PATH                 : /home/irfan/Desktop/Code/Datasets/COCO/val2017/\n",
      "TEST_BATCH_SIZE               : 4\n",
      "TEST_INPUT_SIZE               : 224\n",
      "TEST_DATA_AUG                 : False\n",
      "TEST_DECTECTED_IMAGE_PATH     : \n",
      "TEST_SCORE_THRESHOLD          : 0.3\n",
      "TEST_IOU_THRESHOLD            : 0.45\n",
      "CLASS_NAMES                   : {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorbike', 4: 'aeroplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic-light', 10: 'fire-hydrant', 11: 'stop-sign', 12: 'parking-meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports-ball', 33: 'kite', 34: 'baseball-bat', 35: 'baseball-glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis-racket', 39: 'bottle', 40: 'wine-glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot-dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'sofa', 58: 'pottedplant', 59: 'bed', 60: 'diningtable', 61: 'toilet', 62: 'tvmonitor', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell-phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy-bear', 78: 'hair-drier', 79: 'toothbrush'}\n",
      "NUM_CLASS                     : 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if yolo_test == True or yolo_eval== True or seg_test==True or sanity_check== True or debug == True:\n",
    "    save_notebook = False\n",
    "else:\n",
    "    save_notebook = True\n",
    "    \n",
    "if save_notebook == True:\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER): os.makedirs(TRAIN_CHECKPOINTS_FOLDER)\n",
    "    with open(TRAIN_CHECKPOINTS_FOLDER +'/params.txt','w') as file:\n",
    "        log_str='Time '.ljust(30)+': '+str(datetime.now())+'\\n'\n",
    "        for key in list(params.keys())[:-1]:\n",
    "            if key[:2] != '__':\n",
    "                log_str += key.ljust(30)+': ' + str(params[key])+'\\n'\n",
    "        print(log_str)\n",
    "        file.write(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "365c8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System time :  1653589967.573591\n"
     ]
    }
   ],
   "source": [
    "if save_notebook == True:\n",
    "    curr_time=time.time()\n",
    "    print('System time : ',curr_time)\n",
    "    #%autosave 1\n",
    "    #time.sleep(3)\n",
    "    \n",
    "    os.system(f\"cp yolo-v3.ipynb {TRAIN_CHECKPOINTS_FOLDER}/yolo-v3_{str(curr_time)}.ipynb\")\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER+'/yolo/'): os.makedirs(TRAIN_CHECKPOINTS_FOLDER+'/yolo/')\n",
    "    files = glob.glob('yolo/*')\n",
    "    for file in files:\n",
    "        try : os.system(f\"cp -r {file} {TRAIN_CHECKPOINTS_FOLDER}/{file}\")\n",
    "        except PermissionError:\n",
    "            print('PermissionError : ',file)\n",
    "    #%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d18cbab-0ce2-40a0-9533-3be079b0dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applications\n",
      "cocoapi\n",
      "data_exp.ipynb\n",
      "extra\n",
      "logs\n",
      "loss_analysis.ipynb\n",
      "mAP\n",
      "mobilenet_wts\n",
      "model_data\n",
      "net.ipynb\n",
      "old\n",
      "params.json\n",
      "__pycache__\n",
      "run\n",
      "run.sh\n",
      "socket_io\n",
      "test.hdf5\n",
      "vis_plot_detail.ipynb\n",
      "voc_to_coco.ipynb\n",
      "yolo\n",
      "yolo_v31\n",
      "yolo-v31.ipynb\n",
      "yolo-v3-grad_norm.ipynb\n",
      "yolo-v3-inf_custom.ipynb\n",
      "yolo-v3-inference.ipynb\n",
      "yolo-v3-inf.ipynb\n",
      "yolo-v3.ipynb\n",
      "yolo-v3-log-epochs.ipynb\n",
      "yolo-v3-mod.ipynb\n",
      "yolo-v3-mod.py\n",
      "yolo-v3.nbconvert.ipynb\n",
      "yolo-v3-pc_grad.ipynb\n",
      "yolo-v3.py\n",
      "yolo-v3-voc.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2804844f-6f8c-4a03-893d-7f8f17915683",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#yolo = YoloModel(training=True,N=1)\n",
    "#yolo_model=yolo.get_model()\n",
    "#yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497caaac-85b4-4346-9c9f-9c8489b06038",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if yolo_test == True:\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs'): os.makedirs(TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs')\n",
    "    #video_path   = \"./IMAGES/test.mp4\"\n",
    "    img_path   = \"/home/irfan/Desktop/Code/Datasets/COCO/val2017/\"\n",
    "    yolo = YoloModel()\n",
    "    yolo_model=yolo.get_model()\n",
    "    decoder = YoloDecodeNetout()\n",
    "    for i,layer in enumerate(yolo_model.layers):\n",
    "        yolo_model.get_layer(layer.name).trainable=False\n",
    "    #decoder.detect_video(yolo_model, video_path, input_size=288, show=True, score_threshold=0.1, iou_threshold=0.2, rectangle_colors='')\n",
    "    decoder.detect_images(yolo_model, img_path, output_path=TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs/',input_size=256, show=True, score_threshold=0.3, iou_threshold=0.5, rectangle_colors='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c571bfe5-b47c-4cdd-93dd-6955358d4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/irfan/Desktop/Code/Datasets/COCO/val2017/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9533ec87-1dba-4487-9518-3362db8150e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yolo_eval == True:\n",
    "    res_dict=[]\n",
    "    for min_overlap in list(range(50,100,5)):\n",
    "        min_overlap = min_overlap/100\n",
    "        for iou_threshold in [0.1]:#,0.2,0.3,0.3,0.4,0.5]:#[0.1,0.2,0.3,0.4,0.5]:\n",
    "            for score_threshold in [0.0]:#,0.05,0.1,0.2]:#[0.1,0.2,0.3,0.4,0.5]:\n",
    "                yolo = YoloModel()\n",
    "                yolo_model=yolo.get_model()\n",
    "                decoder = YoloDecodeNetout()\n",
    "\n",
    "                testset = Dataset('test')\n",
    "                out=get_mAP(yolo_model, testset, decoder, min_overlap= min_overlap ,score_threshold=score_threshold, iou_threshold=iou_threshold, TEST_INPUT_SIZE=YOLO_INPUT_SIZE)\n",
    "                res_dict+=[[out,min_overlap,score_threshold,iou_threshold]]\n",
    "                print(res_dict)\n",
    "    \n",
    "    with open(TRAIN_CHECKPOINTS_FOLDER+'/scores_0.1_0.0001.pkl','wb') as file:\n",
    "        pickle.dump(res_dict,file)\n",
    "    print(sum([res[0] for res in res_dict])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a921408",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_test == True:\n",
    "    trainset = Dataset('train')\n",
    "    testset = Dataset('test')\n",
    "    \n",
    "    yolo = YoloModel()\n",
    "    yolo_model=yolo.get_model()\n",
    "        \n",
    "    for image , label in trainset:\n",
    "        break\n",
    "        \n",
    "    out = yolo_model.predict(image)\n",
    "    plt.imshow(label[3][1].max(axis=-1))\n",
    "    plt.show()\n",
    "    plt.imshow(out[2][1][:,:,:len(CLASS_NAMES)].max(axis=-1))\n",
    "    plt.show()\n",
    "\n",
    "    for image , label in testset:\n",
    "        break\n",
    "    out = yolo_model.predict(image)\n",
    "    plt.imshow(label[3][1].max(axis=-1))\n",
    "    plt.show()\n",
    "    plt.imshow(out[2][1][:,:,:len(CLASS_NAMES)].max(axis=-1))\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.imshow(label[3][1])\n",
    "    #plt.show()\n",
    "    #plt.imshow(out[2][0][:,:].max(axis=-1))\n",
    "    #plt.imshow(image[0])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb97878",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check == True:\n",
    "    trainset = Dataset('train')\n",
    "    testset  = Dataset('test')\n",
    "    for train_img, train_label in trainset:\n",
    "        print('..')\n",
    "        break\n",
    "    for test_img, test_label in testset:\n",
    "        print('...')\n",
    "        break\n",
    "    decoder = YoloDecodeNetout()\n",
    "    pred_bbox = [label[0][0] for label in train_label]#[label_sbbox, label_mbbox, label_lbbox]\n",
    "    \n",
    "    pred_bbox = [np.reshape(x, (-1, np.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = np.concatenate(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = decoder.decode_boxes(pred_bbox, train_img[0], YOLO_INPUT_SIZE, TEST_SCORE_THRESHOLD)\n",
    "    bboxes = decoder.nms(bboxes, TEST_IOU_THRESHOLD, method='nms')\n",
    "\n",
    "    out=Utils.draw_bbox(train_img[0], bboxes, conf=True,show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False)\n",
    "    plt.imshow(train_img[0])\n",
    "    plt.show()\n",
    "    plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f45972",
   "metadata": {},
   "outputs": [],
   "source": [
    "wts_check=False\n",
    "if wts_check== True:\n",
    "    wts = yolo_model.trainable_weights\n",
    "    for i in range(len(wts)):\n",
    "        if len(wts[i].shape) and wts[i].shape[0]==3: \n",
    "            print(wts[i].shape)\n",
    "            _wts = tf.abs(wts[i])\n",
    "            vector = tf.reduce_sum(_wts,axis=[0,1])\n",
    "            norm_rev_vec = 1 - vector/tf.reduce_max(vector)\n",
    "            plt.imshow(norm_rev_vec,cmap='gray')\n",
    "            print(tf.reduce_mean(norm_rev_vec))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443e3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_dict_obj(dict):\n",
    "        def tf2np(self,val):\n",
    "            if hasattr(val,'numpy'):\n",
    "                val=val.numpy()\n",
    "            else:\n",
    "                if val==None: val=0\n",
    "            return val\n",
    "\n",
    "        def sum_update(self,c_dict):\n",
    "            for key,val in c_dict.items():\n",
    "                if key in list(self.keys()):\n",
    "                    self[key]+=self.tf2np(c_dict[key])\n",
    "                else:\n",
    "                    self[key]=self.tf2np(c_dict[key])\n",
    "\n",
    "\n",
    "        def ext_update(self,c_dict,_ext='_ext'):\n",
    "            for key,val in c_dict.items():\n",
    "                     self[_ext+key]=self.tf2np(val)\n",
    "\n",
    "        def divide(self,div_val):\n",
    "            for key,val in self.items():\n",
    "                if type(div_val)==dict or type(div_val)==loss_dict_obj:\n",
    "                    self[key]/=div_val[key]\n",
    "                else:\n",
    "                    self[key]/=div_val\n",
    "\n",
    "        def _sum(self):\n",
    "            total=0\n",
    "            for val in self.values():\n",
    "                total+=val\n",
    "            return total\n",
    "\n",
    "        def copy_keys(self,c_dict,keys):\n",
    "            for key in keys:\n",
    "                self[key]=c_dict[key]\n",
    "\n",
    "        def apply(self,func):\n",
    "            for key in self.keys():\n",
    "                self[key]=self.tf2np(func(self[key]))\n",
    "\n",
    "def get_best_model_path(exp_dir = 'logs/exp-D101'):\n",
    "    paths = glob.glob(f'{exp_dir}/model/epoch_*')\n",
    "    arg = np.argmin([float(path.split('_')[-1]) for path in paths])\n",
    "    best_model_path = paths[arg] + '/weights'\n",
    "    print(\"Found best model path : \",best_model_path)\n",
    "    return best_model_path\n",
    "\n",
    "\n",
    "def save_loss_logs(loss_dict,epoch):\n",
    "    if epoch==0: log_str=','.join(list(loss_dict.keys()))+'\\n'\n",
    "    else : log_str = ''\n",
    "    log_str += ','.join(list(map(str,loss_dict.values())))+'\\n'\n",
    "\n",
    "    with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'loss.csv'),'a+') as file:\n",
    "        file.write(log_str)\n",
    "            \n",
    "def save_std_logs(train_loss,all_logs,epoch):\n",
    "    if epoch==0 : log_str='epoch,'+','.join(list(train_loss.keys()))+'\\n'\n",
    "    else : log_str = ''\n",
    "            \n",
    "    for _ind in range(no_train_batch): \n",
    "        log_str += str(epoch)+','\n",
    "        log_str += ','.join(list(map(str,all_logs[_ind])))+'\\n'\n",
    "\n",
    "    with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'all_loss.csv'),'a+') as file:\n",
    "        file.write(log_str)\n",
    "        \n",
    "def save_sample_losses(sample_losses,epoch):\n",
    "    \n",
    "    for _lind,loss_name in zip([0,1],['det','seg']):\n",
    "        if TRAIN_LOSS_WTS[_lind]:\n",
    "            if epoch==0 : log_str='epoch,'+','.join(list(map(str,range(TRAIN_BATCH_SIZE))))+'\\n'\n",
    "            else : log_str = ''\n",
    "            for _ind in range(no_train_batch): \n",
    "                log_str += str(epoch)+','\n",
    "                log_str += ','.join(list(map(str,sample_losses[_ind][_lind].numpy())))+'\\n'\n",
    "\n",
    "            with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'sample_loss_'+loss_name+'.csv'),'a+') as file:\n",
    "                file.write(log_str)  \n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(image_data, target,epoch,alpha=1.0):\n",
    "        train_loss_dict = loss_dict_obj()\n",
    "        sample_loss_dict= loss_dict_obj()\n",
    "        sample_seg_losses = sample_det_losses = det_loss = seg_loss = kl_coef = 0.0\n",
    "        giou_loss = conf_loss = prob_loss = 0.0\n",
    "        gradients1 = gradients2 = [None]*len(yolo_model.trainable_variables)\n",
    "        grad_variance1 = grad_variance2 = []\n",
    "        smp_grads_det = [] ; smp_grads_seg = []\n",
    "        yolo_model.training = True\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch([yolo_model.trainable_variables])\n",
    "            pred_result = yolo_model(image_data)\n",
    "            pred_result = yolo.decode_output(pred_result)\n",
    "            del image_data\n",
    "            \n",
    "            if TRAIN_LOSS_WTS[0]:\n",
    "                for i in range(NO_OF_GRID):\n",
    "                    conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                    #tf.print(pred.shape,conv.shape,target[i][0].shape)\n",
    "                    loss_dict, _giou_loss , _conf_loss , _prob_loss = calc_yolo_loss(pred, conv, *target[i], i)\n",
    "                    train_loss_dict.sum_update(loss_dict)\n",
    "                    \n",
    "                    giou_loss += 1/NO_OF_GRID * _giou_loss\n",
    "                    conf_loss += 1/NO_OF_GRID * _conf_loss\n",
    "                    prob_loss += 1/NO_OF_GRID * _prob_loss\n",
    "                    \n",
    "                loss =  (MTL_LOSS_WTS[0] * giou_loss + MTL_LOSS_WTS[1] * conf_loss)\n",
    "                grads_1 = tape.gradient(loss , yolo_model.trainable_variables)\n",
    "                grads_2 = tape.gradient(MTL_LOSS_WTS[2] * prob_loss , yolo_model.trainable_variables)\n",
    "                \n",
    "        return train_loss_dict, [grads_1,grads_2]\n",
    "\n",
    "def reduce_prob(x):\n",
    "    mean = tf.math.reduce_mean(x,axis=0)\n",
    "    #std  = tf.math.reduce_std(x,axis=0)\n",
    "    var  = tf.reduce_mean(tf.square(x - mean),axis=0) + 1e-20\n",
    "    p_x  = tf.square((x - mean)) / var\n",
    "    p_x  = tf.exp(-0.5*p_x)\n",
    "    coef = 1/(tf.sqrt(2*np.pi)*var)\n",
    "    p_x  = coef * p_x\n",
    "    return (p_x/tf.reduce_sum(p_x,axis=0)) + 1e-20\n",
    "\n",
    "def reduce_kl_div(x,y):\n",
    "    p_x = reduce_prob(x)\n",
    "    p_y = reduce_prob(y)\n",
    "    kl_div = p_x * tf.math.log(p_x / p_y)\n",
    "    kl_div = tf.reduce_sum(kl_div,axis=0)\n",
    "    kl_div = tf.clip_by_value(kl_div,0,1)\n",
    "    return kl_div\n",
    "\n",
    "def get_probs(_grads,_grads_conf_1):\n",
    "    coef_1 = 1/_vars\n",
    "    coef_2 = tf.square(_grads - _means)/_vars\n",
    "    probs  = coef_1 * tf.exp(-0.5*coef_2)\n",
    "    probs  = (probs / tf.reduce_max(probs)) + 1e-10\n",
    "    return probs\n",
    "\n",
    "def get_disc_probs(_grads,_confs):\n",
    "    sign      = np.sign(_confs)\n",
    "    pos_prob  = np.mean((sign + 1.0)/2.0,axis=0)\n",
    "    neg_prob  = np.mean(np.abs(sign - 1.0)/2.0,axis=0)\n",
    "    pos_mask  = np.uint8(_grads>=0)\n",
    "    neg_mask  = np.uint8(_grads<0)\n",
    "    \n",
    "    _grads    = pos_mask * pos_prob + neg_mask * neg_prob\n",
    "    return _grads\n",
    "\n",
    "def reduce_disc_kl_div(p_x,p_y):\n",
    "    kl_div = p_x * tf.math.log(p_x / p_y)\n",
    "    kl_div = tf.reduce_sum(kl_div,axis=0)\n",
    "    kl_div = tf.clip_by_value(kl_div,0,1)\n",
    "    return kl_div\n",
    "\n",
    "#@tf.function    \n",
    "def train_batch(image_data,target,frozen=False):\n",
    "    global model_flag, model_flag_aux\n",
    "    NO_MINI_BATCH = TRAIN_BATCH_SIZE//TRAIN_MINI_BATCH_SIZE\n",
    "    gradients1 = [0.0]*len(yolo_model.trainable_variables)\n",
    "    gradients2 = [0.0]*len(yolo_model.trainable_variables)\n",
    "    loss_wts_grads = [0.0]* 4 #MTL_NO_OF_BLOCKS\n",
    "    norms_matrix   = [0.0]* 4\n",
    "    gradient_vars1 = [0.0] * MTL_NO_OF_SHARED_LAYERS\n",
    "    gradient_vars2 = [0.0] * MTL_NO_OF_SHARED_LAYERS\n",
    "    train_loss = loss_dict_obj(); smp_loss = loss_dict_obj()\n",
    "    \n",
    "    smp_grads_det = []\n",
    "    smp_grads_seg = []\n",
    "    for ind in range(0,NO_MINI_BATCH):\n",
    "        mbatch_image,mbatch_target = get_mini_batch(image_data,target,ind,TRAIN_MINI_BATCH_SIZE)\n",
    "        mbatch_train_loss, mbatch_grads = train_step(mbatch_image, mbatch_target,epoch)\n",
    "        \n",
    "        _coef = 1/NO_MINI_BATCH\n",
    "        for ind,[lgrad1,lgrad2] in enumerate(zip(*mbatch_grads)):           \n",
    "            if type(lgrad1) == type(None) : lgrad1 = 0.0\n",
    "            if type(lgrad2) == type(None) : lgrad2 = 0.0\n",
    "            gradients1[ind] += _coef * lgrad1\n",
    "            gradients2[ind] += _coef * lgrad2\n",
    "                   \n",
    "        train_loss.sum_update(mbatch_train_loss)\n",
    "    train_loss.divide(NO_MINI_BATCH)    \n",
    "    \n",
    "    kl_divs = []\n",
    "    for ind in range(len(gradients1)):\n",
    "        gradients1[ind] = gradients1[ind] + gradients2[ind]            \n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients1, yolo_model.trainable_variables))\n",
    "        \n",
    "    return train_loss,smp_grads_det,smp_grads_seg,norms_matrix\n",
    "\n",
    "def add_ext(loss_dict,_ext='val_'):\n",
    "    _loss_dict = {}\n",
    "    for key in loss_dict.keys():\n",
    "          _loss_dict[_ext+key]=loss_dict[key]\n",
    "    return _loss_dict\n",
    "\n",
    "#@tf.function\n",
    "def validate_step(image_data, target):\n",
    "    val_loss_dict = loss_dict_obj()\n",
    "    \n",
    "    pred_result = yolo_model(image_data)\n",
    "    pred_result = yolo.decode_output(pred_result,batch_size=TEST_BATCH_SIZE)\n",
    "    del image_data\n",
    "\n",
    "    for i in range(NO_OF_GRID):\n",
    "        conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "        loss_dict, _, _,_ = calc_yolo_loss(pred, conv, *target[i], i,batch_size=TEST_BATCH_SIZE)\n",
    "        loss_dict = add_ext(loss_dict,_ext='val_')\n",
    "        val_loss_dict.sum_update(loss_dict)\n",
    "\n",
    "    if TRAIN_USE_DST or TRAIN_USE_SEG:\n",
    "        seg_pred     = pred_result[2*(grid -1)+2:]\n",
    "        seg_label    = target[3:]\n",
    "\n",
    "        loss_dict, _, _,_ = calc_seg_loss(seg_label,seg_pred)\n",
    "        loss_dict = add_ext(loss_dict,_ext='val_')\n",
    "        val_loss_dict.sum_update(loss_dict)\n",
    "\n",
    "    del pred_result, target\n",
    "        \n",
    "    return val_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b49e20-3ef2-4d8f-863c-f26c3a42ab55",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 03:32:47.777364: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-27 03:32:47.777501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.777657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2022-05-27 03:32:47.777696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-27 03:32:47.777717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-27 03:32:47.777732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-27 03:32:47.777746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-27 03:32:47.777760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-27 03:32:47.777774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-27 03:32:47.777788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-27 03:32:47.777802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-27 03:32:47.777852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.777977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:47.778060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-05-27 03:32:47.778089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-27 03:32:48.134767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-27 03:32:48.134791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-05-27 03:32:48.134797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-05-27 03:32:48.134937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:48.135076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:48.135185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-27 03:32:48.135275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2165 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "getting wts from Conv1  === setting weights from Conv1 to block0_conv1\n",
      "getting wts from bn_Conv1  === setting weights from bn_Conv1 to block0_bn_conv1\n",
      "getting wts from expanded_conv_depthwise  === setting weights from expanded_conv_depthwise to block_xx_expanded_conv_depthwise\n",
      "getting wts from expanded_conv_depthwise_BN  === setting weights from expanded_conv_depthwise_BN to block_xx_expanded_conv_depthwise_BN\n",
      "getting wts from expanded_conv_project  === setting weights from expanded_conv_project to block_xx_expanded_conv_project\n",
      "getting wts from expanded_conv_project_BN  === setting weights from expanded_conv_project_BN to block_xx_expanded_conv_project_BN\n",
      "getting wts from block_1_expand  === setting weights from block_1_expand to block_1_expand\n",
      "getting wts from block_1_expand_BN  === setting weights from block_1_expand_BN to block_1_expand_BN\n",
      "getting wts from block_1_depthwise  === setting weights from block_1_depthwise to block_1_depthwise\n",
      "getting wts from block_1_depthwise_BN  === setting weights from block_1_depthwise_BN to block_1_depthwise_BN\n",
      "getting wts from block_1_project  === setting weights from block_1_project to block_1_project\n",
      "getting wts from block_1_project_BN  === setting weights from block_1_project_BN to block_1_project_BN\n",
      "getting wts from block_2_expand  === setting weights from block_2_expand to block_2_expand\n",
      "getting wts from block_2_expand_BN  === setting weights from block_2_expand_BN to block_2_expand_BN\n",
      "getting wts from block_2_depthwise  === setting weights from block_2_depthwise to block_2_depthwise\n",
      "getting wts from block_2_depthwise_BN  === setting weights from block_2_depthwise_BN to block_2_depthwise_BN\n",
      "getting wts from block_2_project  === setting weights from block_2_project to block_2_project\n",
      "getting wts from block_2_project_BN  === setting weights from block_2_project_BN to block_2_project_BN\n",
      "getting wts from block_3_expand  === setting weights from block_3_expand to block_3_expand\n",
      "getting wts from block_3_expand_BN  === setting weights from block_3_expand_BN to block_3_expand_BN\n",
      "getting wts from block_3_depthwise  === setting weights from block_3_depthwise to block_3_depthwise\n",
      "getting wts from block_3_depthwise_BN  === setting weights from block_3_depthwise_BN to block_3_depthwise_BN\n",
      "getting wts from block_3_project  === setting weights from block_3_project to block_3_project\n",
      "getting wts from block_3_project_BN  === setting weights from block_3_project_BN to block_3_project_BN\n",
      "getting wts from block_4_expand  === setting weights from block_4_expand to block_4_expand\n",
      "getting wts from block_4_expand_BN  === setting weights from block_4_expand_BN to block_4_expand_BN\n",
      "getting wts from block_4_depthwise  === setting weights from block_4_depthwise to block_4_depthwise\n",
      "getting wts from block_4_depthwise_BN  === setting weights from block_4_depthwise_BN to block_4_depthwise_BN\n",
      "getting wts from block_4_project  === setting weights from block_4_project to block_4_project\n",
      "getting wts from block_4_project_BN  === setting weights from block_4_project_BN to block_4_project_BN\n",
      "getting wts from block_5_expand  === setting weights from block_5_expand to block_5_expand\n",
      "getting wts from block_5_expand_BN  === setting weights from block_5_expand_BN to block_5_expand_BN\n",
      "getting wts from block_5_depthwise  === setting weights from block_5_depthwise to block_5_depthwise\n",
      "getting wts from block_5_depthwise_BN  === setting weights from block_5_depthwise_BN to block_5_depthwise_BN\n",
      "getting wts from block_5_project  === setting weights from block_5_project to block_5_project\n",
      "getting wts from block_5_project_BN  === setting weights from block_5_project_BN to block_5_project_BN\n",
      "getting wts from block_6_expand  === setting weights from block_6_expand to block_6_expand\n",
      "getting wts from block_6_expand_BN  === setting weights from block_6_expand_BN to block_6_expand_BN\n",
      "getting wts from block_6_depthwise  === setting weights from block_6_depthwise to block_6_depthwise\n",
      "getting wts from block_6_depthwise_BN  === setting weights from block_6_depthwise_BN to block_6_depthwise_BN\n",
      "getting wts from block_6_project  === setting weights from block_6_project to block_6_project\n",
      "getting wts from block_6_project_BN  === setting weights from block_6_project_BN to block_6_project_BN\n",
      "getting wts from block_7_expand  === setting weights from block_7_expand to block_7_expand\n",
      "getting wts from block_7_expand_BN  === setting weights from block_7_expand_BN to block_7_expand_BN\n",
      "getting wts from block_7_depthwise  === setting weights from block_7_depthwise to block_7_depthwise\n",
      "getting wts from block_7_depthwise_BN  === setting weights from block_7_depthwise_BN to block_7_depthwise_BN\n",
      "getting wts from block_7_project  === setting weights from block_7_project to block_7_project\n",
      "getting wts from block_7_project_BN  === setting weights from block_7_project_BN to block_7_project_BN\n",
      "getting wts from block_8_expand  === setting weights from block_8_expand to block_8_expand\n",
      "getting wts from block_8_expand_BN  === setting weights from block_8_expand_BN to block_8_expand_BN\n",
      "getting wts from block_8_depthwise  === setting weights from block_8_depthwise to block_8_depthwise\n",
      "getting wts from block_8_depthwise_BN  === setting weights from block_8_depthwise_BN to block_8_depthwise_BN\n",
      "getting wts from block_8_project  === setting weights from block_8_project to block_8_project\n",
      "getting wts from block_8_project_BN  === setting weights from block_8_project_BN to block_8_project_BN\n",
      "getting wts from block_9_expand  === setting weights from block_9_expand to block_9_expand\n",
      "getting wts from block_9_expand_BN  === setting weights from block_9_expand_BN to block_9_expand_BN\n",
      "getting wts from block_9_depthwise  === setting weights from block_9_depthwise to block_9_depthwise\n",
      "getting wts from block_9_depthwise_BN  === setting weights from block_9_depthwise_BN to block_9_depthwise_BN\n",
      "getting wts from block_9_project  === setting weights from block_9_project to block_9_project\n",
      "getting wts from block_9_project_BN  === setting weights from block_9_project_BN to block_9_project_BN\n",
      "getting wts from block_10_expand  === setting weights from block_10_expand to block_10_expand\n",
      "getting wts from block_10_expand_BN  === setting weights from block_10_expand_BN to block_10_expand_BN\n",
      "getting wts from block_10_depthwise  === setting weights from block_10_depthwise to block_10_depthwise\n",
      "getting wts from block_10_depthwise_BN  === setting weights from block_10_depthwise_BN to block_10_depthwise_BN\n",
      "getting wts from block_10_project  === setting weights from block_10_project to block_10_project\n",
      "getting wts from block_10_project_BN  === setting weights from block_10_project_BN to block_10_project_BN\n",
      "getting wts from block_11_expand  === setting weights from block_11_expand to block_11_expand\n",
      "getting wts from block_11_expand_BN  === setting weights from block_11_expand_BN to block_11_expand_BN\n",
      "getting wts from block_11_depthwise  === setting weights from block_11_depthwise to block_11_depthwise\n",
      "getting wts from block_11_depthwise_BN  === setting weights from block_11_depthwise_BN to block_11_depthwise_BN\n",
      "getting wts from block_11_project  === setting weights from block_11_project to block_11_project\n",
      "getting wts from block_11_project_BN  === setting weights from block_11_project_BN to block_11_project_BN\n",
      "getting wts from block_12_expand  === setting weights from block_12_expand to block_12_expand\n",
      "getting wts from block_12_expand_BN  === setting weights from block_12_expand_BN to block_12_expand_BN\n",
      "getting wts from block_12_depthwise  === setting weights from block_12_depthwise to block_12_depthwise\n",
      "getting wts from block_12_depthwise_BN  === setting weights from block_12_depthwise_BN to block_12_depthwise_BN\n",
      "getting wts from block_12_project  === setting weights from block_12_project to block_12_project\n",
      "getting wts from block_12_project_BN  === setting weights from block_12_project_BN to block_12_project_BN\n",
      "getting wts from block_13_expand  === setting weights from block_13_expand to block_13_expand\n",
      "getting wts from block_13_expand_BN  === setting weights from block_13_expand_BN to block_13_expand_BN\n",
      "getting wts from block_13_depthwise  === setting weights from block_13_depthwise to block_13_depthwise\n",
      "getting wts from block_13_depthwise_BN  === setting weights from block_13_depthwise_BN to block_13_depthwise_BN\n",
      "getting wts from block_13_project  === setting weights from block_13_project to block_13_project\n",
      "getting wts from block_13_project_BN  === setting weights from block_13_project_BN to block_13_project_BN\n",
      "getting wts from block_14_expand  === setting weights from block_14_expand to block_14_expand\n",
      "getting wts from block_14_expand_BN  === setting weights from block_14_expand_BN to block_14_expand_BN\n",
      "getting wts from block_14_depthwise  === setting weights from block_14_depthwise to block_14_depthwise\n",
      "getting wts from block_14_depthwise_BN  === setting weights from block_14_depthwise_BN to block_14_depthwise_BN\n",
      "getting wts from block_14_project  === setting weights from block_14_project to block_14_project\n",
      "getting wts from block_14_project_BN  === setting weights from block_14_project_BN to block_14_project_BN\n",
      "getting wts from block_15_expand  === setting weights from block_15_expand to block_15_expand\n",
      "getting wts from block_15_expand_BN  === setting weights from block_15_expand_BN to block_15_expand_BN\n",
      "getting wts from block_15_depthwise  === setting weights from block_15_depthwise to block_15_depthwise\n",
      "getting wts from block_15_depthwise_BN  === setting weights from block_15_depthwise_BN to block_15_depthwise_BN\n",
      "getting wts from block_15_project  === setting weights from block_15_project to block_15_project\n",
      "getting wts from block_15_project_BN  === setting weights from block_15_project_BN to block_15_project_BN\n",
      "getting wts from block_16_expand  === setting weights from block_16_expand to block_16_expand\n",
      "getting wts from block_16_expand_BN  === setting weights from block_16_expand_BN to block_16_expand_BN\n",
      "getting wts from block_16_depthwise  === setting weights from block_16_depthwise to block_16_depthwise\n",
      "getting wts from block_16_depthwise_BN  === setting weights from block_16_depthwise_BN to block_16_depthwise_BN\n",
      "getting wts from block_16_project  === setting weights from block_16_project to block_16_project\n",
      "getting wts from block_16_project_BN  === setting weights from block_16_project_BN to block_16_project_BN\n",
      "getting wts from Conv_1  === setting weights from Conv_1 to block_ext_vonv_1\n",
      "getting wts from Conv_1_bn  === setting weights from Conv_1_bn to block_ext_conv_1_bn\n",
      "getting wts from predictions Model: \"mobile_net_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block0_conv1 (Conv2D)        multiple                  864       \n",
      "_________________________________________________________________\n",
      "block0_bn_conv1 (BatchNormal multiple                  128       \n",
      "_________________________________________________________________\n",
      "block0_conv1_relu (ReLU)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "inv_res_block_0 (_inverted_r multiple                  992       \n",
      "_________________________________________________________________\n",
      "inv_res_block_1 (_inverted_r multiple                  5568      \n",
      "_________________________________________________________________\n",
      "inv_res_block_2 (_inverted_r multiple                  9456      \n",
      "_________________________________________________________________\n",
      "inv_res_block_3 (_inverted_r multiple                  10640     \n",
      "_________________________________________________________________\n",
      "inv_res_block_4 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_5 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_6 (_inverted_r multiple                  21952     \n",
      "_________________________________________________________________\n",
      "inv_res_block_7 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_8 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_9 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_10 (_inverted_ multiple                  68352     \n",
      "_________________________________________________________________\n",
      "inv_res_block_11 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_12 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_13 (_inverted_ multiple                  157888    \n",
      "_________________________________________________________________\n",
      "inv_res_block_14 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_15 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_16 (_inverted_ multiple                  478400    \n",
      "_________________________________________________________________\n",
      "block_ext_vonv_1 (Conv2D)    multiple                  409600    \n",
      "_________________________________________________________________\n",
      "block_ext_conv_1_bn (BatchNo multiple                  5120      \n",
      "_________________________________________________________________\n",
      "block_ext_out_relu (ReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              multiple                  2949120   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              multiple                  65280     \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              multiple                  16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  36928     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  368640    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  587520    \n",
      "=================================================================\n",
      "Total params: 6,284,160\n",
      "Trainable params: 6,248,896\n",
      "Non-trainable params: 35,264\n",
      "_________________________________________________________________\n",
      "0 block0_conv1/kernel:0\n",
      "1 block0_bn_conv1/gamma:0\n",
      "2 block0_bn_conv1/beta:0\n",
      "3 inv_res_block_0/block_xx_expanded_conv_depthwise/depthwise_kernel:0\n",
      "4 inv_res_block_0/block_xx_expanded_conv_depthwise_BN/gamma:0\n",
      "5 inv_res_block_0/block_xx_expanded_conv_depthwise_BN/beta:0\n",
      "6 inv_res_block_0/block_xx_expanded_conv_project/kernel:0\n",
      "7 inv_res_block_0/block_xx_expanded_conv_project_BN/gamma:0\n",
      "8 inv_res_block_0/block_xx_expanded_conv_project_BN/beta:0\n",
      "9 inv_res_block_1/block_1_expand/kernel:0\n",
      "10 inv_res_block_1/block_1_expand_BN/gamma:0\n",
      "11 inv_res_block_1/block_1_expand_BN/beta:0\n",
      "12 inv_res_block_1/block_1_depthwise/depthwise_kernel:0\n",
      "13 inv_res_block_1/block_1_depthwise_BN/gamma:0\n",
      "14 inv_res_block_1/block_1_depthwise_BN/beta:0\n",
      "15 inv_res_block_1/block_1_project/kernel:0\n",
      "16 inv_res_block_1/block_1_project_BN/gamma:0\n",
      "17 inv_res_block_1/block_1_project_BN/beta:0\n",
      "18 inv_res_block_2/block_2_expand/kernel:0\n",
      "19 inv_res_block_2/block_2_expand_BN/gamma:0\n",
      "20 inv_res_block_2/block_2_expand_BN/beta:0\n",
      "21 inv_res_block_2/block_2_depthwise/depthwise_kernel:0\n",
      "22 inv_res_block_2/block_2_depthwise_BN/gamma:0\n",
      "23 inv_res_block_2/block_2_depthwise_BN/beta:0\n",
      "24 inv_res_block_2/block_2_project/kernel:0\n",
      "25 inv_res_block_2/block_2_project_BN/gamma:0\n",
      "26 inv_res_block_2/block_2_project_BN/beta:0\n",
      "27 inv_res_block_3/block_3_expand/kernel:0\n",
      "28 inv_res_block_3/block_3_expand_BN/gamma:0\n",
      "29 inv_res_block_3/block_3_expand_BN/beta:0\n",
      "30 inv_res_block_3/block_3_depthwise/depthwise_kernel:0\n",
      "31 inv_res_block_3/block_3_depthwise_BN/gamma:0\n",
      "32 inv_res_block_3/block_3_depthwise_BN/beta:0\n",
      "33 inv_res_block_3/block_3_project/kernel:0\n",
      "34 inv_res_block_3/block_3_project_BN/gamma:0\n",
      "35 inv_res_block_3/block_3_project_BN/beta:0\n",
      "36 inv_res_block_4/block_4_expand/kernel:0\n",
      "37 inv_res_block_4/block_4_expand_BN/gamma:0\n",
      "38 inv_res_block_4/block_4_expand_BN/beta:0\n",
      "39 inv_res_block_4/block_4_depthwise/depthwise_kernel:0\n",
      "40 inv_res_block_4/block_4_depthwise_BN/gamma:0\n",
      "41 inv_res_block_4/block_4_depthwise_BN/beta:0\n",
      "42 inv_res_block_4/block_4_project/kernel:0\n",
      "43 inv_res_block_4/block_4_project_BN/gamma:0\n",
      "44 inv_res_block_4/block_4_project_BN/beta:0\n",
      "45 inv_res_block_5/block_5_expand/kernel:0\n",
      "46 inv_res_block_5/block_5_expand_BN/gamma:0\n",
      "47 inv_res_block_5/block_5_expand_BN/beta:0\n",
      "48 inv_res_block_5/block_5_depthwise/depthwise_kernel:0\n",
      "49 inv_res_block_5/block_5_depthwise_BN/gamma:0\n",
      "50 inv_res_block_5/block_5_depthwise_BN/beta:0\n",
      "51 inv_res_block_5/block_5_project/kernel:0\n",
      "52 inv_res_block_5/block_5_project_BN/gamma:0\n",
      "53 inv_res_block_5/block_5_project_BN/beta:0\n",
      "54 inv_res_block_6/block_6_expand/kernel:0\n",
      "55 inv_res_block_6/block_6_expand_BN/gamma:0\n",
      "56 inv_res_block_6/block_6_expand_BN/beta:0\n",
      "57 inv_res_block_6/block_6_depthwise/depthwise_kernel:0\n",
      "58 inv_res_block_6/block_6_depthwise_BN/gamma:0\n",
      "59 inv_res_block_6/block_6_depthwise_BN/beta:0\n",
      "60 inv_res_block_6/block_6_project/kernel:0\n",
      "61 inv_res_block_6/block_6_project_BN/gamma:0\n",
      "62 inv_res_block_6/block_6_project_BN/beta:0\n",
      "63 inv_res_block_7/block_7_expand/kernel:0\n",
      "64 inv_res_block_7/block_7_expand_BN/gamma:0\n",
      "65 inv_res_block_7/block_7_expand_BN/beta:0\n",
      "66 inv_res_block_7/block_7_depthwise/depthwise_kernel:0\n",
      "67 inv_res_block_7/block_7_depthwise_BN/gamma:0\n",
      "68 inv_res_block_7/block_7_depthwise_BN/beta:0\n",
      "69 inv_res_block_7/block_7_project/kernel:0\n",
      "70 inv_res_block_7/block_7_project_BN/gamma:0\n",
      "71 inv_res_block_7/block_7_project_BN/beta:0\n",
      "72 inv_res_block_8/block_8_expand/kernel:0\n",
      "73 inv_res_block_8/block_8_expand_BN/gamma:0\n",
      "74 inv_res_block_8/block_8_expand_BN/beta:0\n",
      "75 inv_res_block_8/block_8_depthwise/depthwise_kernel:0\n",
      "76 inv_res_block_8/block_8_depthwise_BN/gamma:0\n",
      "77 inv_res_block_8/block_8_depthwise_BN/beta:0\n",
      "78 inv_res_block_8/block_8_project/kernel:0\n",
      "79 inv_res_block_8/block_8_project_BN/gamma:0\n",
      "80 inv_res_block_8/block_8_project_BN/beta:0\n",
      "81 inv_res_block_9/block_9_expand/kernel:0\n",
      "82 inv_res_block_9/block_9_expand_BN/gamma:0\n",
      "83 inv_res_block_9/block_9_expand_BN/beta:0\n",
      "84 inv_res_block_9/block_9_depthwise/depthwise_kernel:0\n",
      "85 inv_res_block_9/block_9_depthwise_BN/gamma:0\n",
      "86 inv_res_block_9/block_9_depthwise_BN/beta:0\n",
      "87 inv_res_block_9/block_9_project/kernel:0\n",
      "88 inv_res_block_9/block_9_project_BN/gamma:0\n",
      "89 inv_res_block_9/block_9_project_BN/beta:0\n",
      "90 inv_res_block_10/block_10_expand/kernel:0\n",
      "91 inv_res_block_10/block_10_expand_BN/gamma:0\n",
      "92 inv_res_block_10/block_10_expand_BN/beta:0\n",
      "93 inv_res_block_10/block_10_depthwise/depthwise_kernel:0\n",
      "94 inv_res_block_10/block_10_depthwise_BN/gamma:0\n",
      "95 inv_res_block_10/block_10_depthwise_BN/beta:0\n",
      "96 inv_res_block_10/block_10_project/kernel:0\n",
      "97 inv_res_block_10/block_10_project_BN/gamma:0\n",
      "98 inv_res_block_10/block_10_project_BN/beta:0\n",
      "99 inv_res_block_11/block_11_expand/kernel:0\n",
      "100 inv_res_block_11/block_11_expand_BN/gamma:0\n",
      "101 inv_res_block_11/block_11_expand_BN/beta:0\n",
      "102 inv_res_block_11/block_11_depthwise/depthwise_kernel:0\n",
      "103 inv_res_block_11/block_11_depthwise_BN/gamma:0\n",
      "104 inv_res_block_11/block_11_depthwise_BN/beta:0\n",
      "105 inv_res_block_11/block_11_project/kernel:0\n",
      "106 inv_res_block_11/block_11_project_BN/gamma:0\n",
      "107 inv_res_block_11/block_11_project_BN/beta:0\n",
      "108 inv_res_block_12/block_12_expand/kernel:0\n",
      "109 inv_res_block_12/block_12_expand_BN/gamma:0\n",
      "110 inv_res_block_12/block_12_expand_BN/beta:0\n",
      "111 inv_res_block_12/block_12_depthwise/depthwise_kernel:0\n",
      "112 inv_res_block_12/block_12_depthwise_BN/gamma:0\n",
      "113 inv_res_block_12/block_12_depthwise_BN/beta:0\n",
      "114 inv_res_block_12/block_12_project/kernel:0\n",
      "115 inv_res_block_12/block_12_project_BN/gamma:0\n",
      "116 inv_res_block_12/block_12_project_BN/beta:0\n",
      "117 inv_res_block_13/block_13_expand/kernel:0\n",
      "118 inv_res_block_13/block_13_expand_BN/gamma:0\n",
      "119 inv_res_block_13/block_13_expand_BN/beta:0\n",
      "120 inv_res_block_13/block_13_depthwise/depthwise_kernel:0\n",
      "121 inv_res_block_13/block_13_depthwise_BN/gamma:0\n",
      "122 inv_res_block_13/block_13_depthwise_BN/beta:0\n",
      "123 inv_res_block_13/block_13_project/kernel:0\n",
      "124 inv_res_block_13/block_13_project_BN/gamma:0\n",
      "125 inv_res_block_13/block_13_project_BN/beta:0\n",
      "126 inv_res_block_14/block_14_expand/kernel:0\n",
      "127 inv_res_block_14/block_14_expand_BN/gamma:0\n",
      "128 inv_res_block_14/block_14_expand_BN/beta:0\n",
      "129 inv_res_block_14/block_14_depthwise/depthwise_kernel:0\n",
      "130 inv_res_block_14/block_14_depthwise_BN/gamma:0\n",
      "131 inv_res_block_14/block_14_depthwise_BN/beta:0\n",
      "132 inv_res_block_14/block_14_project/kernel:0\n",
      "133 inv_res_block_14/block_14_project_BN/gamma:0\n",
      "134 inv_res_block_14/block_14_project_BN/beta:0\n",
      "135 inv_res_block_15/block_15_expand/kernel:0\n",
      "136 inv_res_block_15/block_15_expand_BN/gamma:0\n",
      "137 inv_res_block_15/block_15_expand_BN/beta:0\n",
      "138 inv_res_block_15/block_15_depthwise/depthwise_kernel:0\n",
      "139 inv_res_block_15/block_15_depthwise_BN/gamma:0\n",
      "140 inv_res_block_15/block_15_depthwise_BN/beta:0\n",
      "141 inv_res_block_15/block_15_project/kernel:0\n",
      "142 inv_res_block_15/block_15_project_BN/gamma:0\n",
      "143 inv_res_block_15/block_15_project_BN/beta:0\n",
      "144 inv_res_block_16/block_16_expand/kernel:0\n",
      "145 inv_res_block_16/block_16_expand_BN/gamma:0\n",
      "146 inv_res_block_16/block_16_expand_BN/beta:0\n",
      "147 inv_res_block_16/block_16_depthwise/depthwise_kernel:0\n",
      "148 inv_res_block_16/block_16_depthwise_BN/gamma:0\n",
      "149 inv_res_block_16/block_16_depthwise_BN/beta:0\n",
      "150 inv_res_block_16/block_16_project/kernel:0\n",
      "151 inv_res_block_16/block_16_project_BN/gamma:0\n",
      "152 inv_res_block_16/block_16_project_BN/beta:0\n",
      "153 block_ext_vonv_1/kernel:0\n",
      "154 block_ext_conv_1_bn/gamma:0\n",
      "155 block_ext_conv_1_bn/beta:0\n",
      "156 conv_1/kernel:0\n",
      "157 batch_normalization/gamma:0\n",
      "158 batch_normalization/beta:0\n",
      "159 conv_2/kernel:0\n",
      "160 conv_3/kernel:0\n",
      "161 batch_normalization_1/gamma:0\n",
      "162 batch_normalization_1/beta:0\n",
      "163 conv2d_transpose/kernel:0\n",
      "164 conv2d_transpose/bias:0\n",
      "165 conv_4/kernel:0\n",
      "166 batch_normalization_2/gamma:0\n",
      "167 batch_normalization_2/beta:0\n",
      "168 conv_4/kernel:0\n"
     ]
    }
   ],
   "source": [
    "if len(TRAIN_LRES_PRE_WTS):\n",
    "    yolo = YoloModel(training=True,input_size=TRAIN_HRES_INPUT_SIZE)\n",
    "    yolo_model = yolo.get_model()\n",
    "    model_path = get_best_model_path(exp_dir=TRAIN_LRES_PRE_WTS)\n",
    "    yolo_model.load_weights(model_path)\n",
    "    \n",
    "    trainset = Dataset('train',input_size=TRAIN_HRES_INPUT_SIZE)\n",
    "    testset  = Dataset('test',input_size=TRAIN_HRES_INPUT_SIZE)\n",
    "\n",
    "else:\n",
    "    yolo = YoloModel(training=True)\n",
    "    yolo_model = yolo.get_model()\n",
    "    trainset = Dataset('train')\n",
    "    testset  = Dataset('test')\n",
    "\n",
    "steps_per_epoch = len(trainset)\n",
    "\n",
    "optimizer  = tf.keras.optimizers.Adam(lr = TRAIN_LR)\n",
    "#loss_opt   =  tf.keras.optimizers.Adam(lr = TRAIN_LOSS_WTS_LR)\n",
    "best_val_loss = 10e8 # should be large at start\n",
    "no_train_batch = trainset.num_batchs\n",
    "no_val_batch  = testset.num_batchs\n",
    "yolo_model.summary()\n",
    "MTL_NO_OF_SHARED_LAYERS = len(yolo_model.trainable_variables)\n",
    "for i,layer in enumerate(yolo_model.trainable_variables):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d38a226-5e0a-4551-ae60-c1b1602aeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_conf_1 = []\n",
    "for layer in yolo_model.trainable_variables[:MTL_NO_OF_SHARED_LAYERS]:\n",
    "    grads_conf_1+=[np.zeros([MTL_GRADS_QLEN]+layer.shape,dtype=np.float32)]\n",
    "    \n",
    "grads_conf_2 = []\n",
    "for layer in yolo_model.trainable_variables[:MTL_NO_OF_SHARED_LAYERS]:\n",
    "    grads_conf_2+=[np.zeros([MTL_GRADS_QLEN]+layer.shape,dtype=np.float32)]\n",
    "\n",
    "prior_loss_wts_matrix = [tf.Variable([1.00,1.00]),\n",
    "                         tf.Variable([1.00,1.00]),\n",
    "                         tf.Variable([1.00,1.00]),\n",
    "                         tf.Variable([1.00,1.00])]#*MTL_NO_OF_BLOCKS\n",
    "\n",
    "loss_rate_matrix = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf45e3f-bffd-4db7-a96a-c9bb129e82d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27, 0.09, 0.16, 0.48)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = np.prod(yolo_model.trainable_variables[0].numpy().shape)\n",
    "n2 = np.prod(yolo_model.trainable_variables[3].numpy().shape)\n",
    "n3 = np.prod(yolo_model.trainable_variables[6].numpy().shape)\n",
    "n4 = np.prod(yolo_model.trainable_variables[9].numpy().shape)\n",
    "n = n1+n2+n3+n4\n",
    "n1/n,n2/n,n3/n,n4/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b83b346-d96c-43b6-bde4-fe5aed9d8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug = True\n",
    "if debug == True:\n",
    "    no_train_batch = 10\n",
    "    no_val_batch   = 3\n",
    "    TRAIN_EPOCHS   = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b807e6d-6fd5-4b12-afc1-9f06b05a5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_gen == True:\n",
    "    print(len(trainset),len(testset))\n",
    "    \n",
    "    os.system(f\"rm -r {TRAIN_DATA_SAVE_PATH}*\")\n",
    "    for ind in trange(no_train_batch):\n",
    "        train_img, train_label  = next(trainset)\n",
    "        path=TRAIN_DATA_SAVE_PATH+'batch_{}.npy'.format(str(ind))\n",
    "        for _i in range(NO_OF_GRID):\n",
    "            train_label[_i][0] = zlib.compress(train_label[_i][0])\n",
    "        np.save(path,[np.uint8(train_img*255.0),train_label]) \n",
    "        \n",
    "    os.system(f\"rm -r {TEST_DATA_SAVE_PATH}*\")\n",
    "    for ind in trange(no_val_batch):\n",
    "        test_img, test_label = next(testset)\n",
    "        path=TEST_DATA_SAVE_PATH+'batch_{}.npy'.format(str(ind))\n",
    "        for _i in range(NO_OF_GRID):\n",
    "            test_label[_i][0] = zlib.compress(test_label[_i][0])\n",
    "        np.save(path,[np.uint8(test_img*255.0),test_label])\n",
    "        \n",
    "    del trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea4a723-2a0d-49b1-8405-009fb507d733",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobile_net_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block0_conv1 (Conv2D)        multiple                  864       \n",
      "_________________________________________________________________\n",
      "block0_bn_conv1 (BatchNormal multiple                  128       \n",
      "_________________________________________________________________\n",
      "block0_conv1_relu (ReLU)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "inv_res_block_0 (_inverted_r multiple                  992       \n",
      "_________________________________________________________________\n",
      "inv_res_block_1 (_inverted_r multiple                  5568      \n",
      "_________________________________________________________________\n",
      "inv_res_block_2 (_inverted_r multiple                  9456      \n",
      "_________________________________________________________________\n",
      "inv_res_block_3 (_inverted_r multiple                  10640     \n",
      "_________________________________________________________________\n",
      "inv_res_block_4 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_5 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_6 (_inverted_r multiple                  21952     \n",
      "_________________________________________________________________\n",
      "inv_res_block_7 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_8 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_9 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_10 (_inverted_ multiple                  68352     \n",
      "_________________________________________________________________\n",
      "inv_res_block_11 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_12 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_13 (_inverted_ multiple                  157888    \n",
      "_________________________________________________________________\n",
      "inv_res_block_14 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_15 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_16 (_inverted_ multiple                  478400    \n",
      "_________________________________________________________________\n",
      "block_ext_vonv_1 (Conv2D)    multiple                  409600    \n",
      "_________________________________________________________________\n",
      "block_ext_conv_1_bn (BatchNo multiple                  5120      \n",
      "_________________________________________________________________\n",
      "block_ext_out_relu (ReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              multiple                  2949120   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              multiple                  65280     \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              multiple                  16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  36928     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  368640    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  587520    \n",
      "=================================================================\n",
      "Total params: 6,284,160\n",
      "Trainable params: 6,248,896\n",
      "Non-trainable params: 35,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ff1b25-a584-4fef-80da-83c00688710c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1 = len(yolo_model.trainable_variables)\n",
    "if TRAIN_FREEZE_EPOCH>0:\n",
    "    for ind,var in enumerate(yolo_model.layers):   \n",
    "        if'block' in var.name:\n",
    "            yolo_model.layers[ind].trainable = False\n",
    "                          \n",
    "l2 = len(yolo_model.trainable_variables)\n",
    "NO_FROZEN_LAYERS = l1-l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a5326e-6a5a-43d2-9bae-bef64aad0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobile_net_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block0_conv1 (Conv2D)        multiple                  864       \n",
      "_________________________________________________________________\n",
      "block0_bn_conv1 (BatchNormal multiple                  128       \n",
      "_________________________________________________________________\n",
      "block0_conv1_relu (ReLU)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "inv_res_block_0 (_inverted_r multiple                  992       \n",
      "_________________________________________________________________\n",
      "inv_res_block_1 (_inverted_r multiple                  5568      \n",
      "_________________________________________________________________\n",
      "inv_res_block_2 (_inverted_r multiple                  9456      \n",
      "_________________________________________________________________\n",
      "inv_res_block_3 (_inverted_r multiple                  10640     \n",
      "_________________________________________________________________\n",
      "inv_res_block_4 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_5 (_inverted_r multiple                  15680     \n",
      "_________________________________________________________________\n",
      "inv_res_block_6 (_inverted_r multiple                  21952     \n",
      "_________________________________________________________________\n",
      "inv_res_block_7 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_8 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_9 (_inverted_r multiple                  55936     \n",
      "_________________________________________________________________\n",
      "inv_res_block_10 (_inverted_ multiple                  68352     \n",
      "_________________________________________________________________\n",
      "inv_res_block_11 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_12 (_inverted_ multiple                  120768    \n",
      "_________________________________________________________________\n",
      "inv_res_block_13 (_inverted_ multiple                  157888    \n",
      "_________________________________________________________________\n",
      "inv_res_block_14 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_15 (_inverted_ multiple                  324160    \n",
      "_________________________________________________________________\n",
      "inv_res_block_16 (_inverted_ multiple                  478400    \n",
      "_________________________________________________________________\n",
      "block_ext_vonv_1 (Conv2D)    multiple                  409600    \n",
      "_________________________________________________________________\n",
      "block_ext_conv_1_bn (BatchNo multiple                  5120      \n",
      "_________________________________________________________________\n",
      "block_ext_out_relu (ReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              multiple                  2949120   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              multiple                  65280     \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              multiple                  16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  36928     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  368640    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              multiple                  587520    \n",
      "=================================================================\n",
      "Total params: 6,284,160\n",
      "Trainable params: 4,025,024\n",
      "Non-trainable params: 2,259,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "943f536f-8c87-4a5c-b88b-d4af40c370c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1849 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 03:33:11.279615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-27 03:33:11.347646: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599990000 Hz\n",
      "2022-05-27 03:33:12.045252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-27 03:33:13.583455: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-05-27 03:33:13.685737: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-05-27 03:33:14.973684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-27 03:33:14.974045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-27 03:33:44.964720: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:44.965044: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:44.965342: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:46.740380: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-05-27 03:33:46.788599: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:46.788701: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:46.794508: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:46.794588: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.19MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:46.796647: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:46.796746: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:46.798411: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:46.798476: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.880869: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.880936: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 769.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.881457: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.881469: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 769.75MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.881961: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.881975: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 47.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.882426: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.882438: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 47.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.882926: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.882938: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.883612: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.883658: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-05-27 03:33:47.884304: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:47.884889: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:48.904129: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:48.904508: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:50.353196: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:50.353587: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:52.450822: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:52.451249: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:52.804684: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:52.805088: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:54.199069: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:54.199534: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:54.553048: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:54.553521: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:55.249787: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:55.250343: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:55.598111: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:55.598497: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.286899: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.287336: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.955513: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.955903: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.956300: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:56.956658: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:57.282837: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:57.283256: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:57.620743: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:57.621120: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:58.298831: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:58.299338: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:58.299769: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:33:58.300195: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:00.985463: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:00.985941: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.671733: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.672239: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.673492: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.673968: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.674424: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.674874: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.675450: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.676000: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.676027: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_grad_filter_ops.cc:1095 : Not found: No algorithm worked!\n",
      "2022-05-27 03:34:01.678095: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.678567: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.679021: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.679497: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.679985: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.680424: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 1.99G (2137260032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-27 03:34:01.680448: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_grad_filter_ops.cc:1095 : Not found: No algorithm worked!\n",
      "  0%|                                                  | 0/1849 [00:53<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " No algorithm worked!\n\t [[node gradient_tape/mobile_net_v2/conv_1/Conv2D/Conv2DBackpropFilter_1 (defined at tmp/ipykernel_94572/591266989.py:113) ]] [Op:__inference_train_step_68658]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mobile_net_v2/conv_1/Conv2D/Conv2DBackpropFilter_1:\n mobile_net_v2/block_ext_out_relu/Relu6 (defined at home/irfan/Desktop/Code/Deep-Learning-For-Robotics/DeepDetect-aux/applications/mobilenet_v2_mod.py:268)\n\nFunction call stack:\ntrain_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m     batch_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(trainset)\n\u001b[1;32m     86\u001b[0m image_data, target \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mlist\u001b[39m(batch_data[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m[batch_dst,batch_seg]\n\u001b[0;32m---> 87\u001b[0m train_loss,ret_det,ret_seg , norms_matrix\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfrozen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frozen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m image_data, target, batch_data\n\u001b[1;32m     90\u001b[0m train_loss_dict\u001b[38;5;241m.\u001b[39msum_update(train_loss)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(image_data, target, frozen)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,NO_MINI_BATCH):\n\u001b[1;32m    174\u001b[0m     mbatch_image,mbatch_target \u001b[38;5;241m=\u001b[39m get_mini_batch(image_data,target,ind,TRAIN_MINI_BATCH_SIZE)\n\u001b[0;32m--> 175\u001b[0m     mbatch_train_loss, mbatch_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmbatch_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmbatch_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     _coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mNO_MINI_BATCH\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ind,[lgrad1,lgrad2] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmbatch_grads)):           \n",
      "File \u001b[0;32m~/Desktop/Mlops-Env/python_38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/Desktop/Mlops-Env/python_38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:894\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[1;32m    898\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Mlops-Env/python_38/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Mlops-Env/python_38/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/Mlops-Env/python_38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m:  No algorithm worked!\n\t [[node gradient_tape/mobile_net_v2/conv_1/Conv2D/Conv2DBackpropFilter_1 (defined at tmp/ipykernel_94572/591266989.py:113) ]] [Op:__inference_train_step_68658]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/mobile_net_v2/conv_1/Conv2D/Conv2DBackpropFilter_1:\n mobile_net_v2/block_ext_out_relu/Relu6 (defined at home/irfan/Desktop/Code/Deep-Learning-For-Robotics/DeepDetect-aux/applications/mobilenet_v2_mod.py:268)\n\nFunction call stack:\ntrain_step\n"
     ]
    }
   ],
   "source": [
    "def seg_to_dst(batch_seg):\n",
    "    batch_dst= np.uint8(255*(batch_seg!=80))\n",
    "    for i in range(len(batch_dst)):\n",
    "        batch_dst[i] = cv2.distanceTransform(batch_dst[i],cv2.DIST_L2,3)\n",
    "    batch_dst = np.float32(batch_dst/ np.sqrt(128**2 + 128**2))\n",
    "    return batch_dst\n",
    "\n",
    "#@tf.function\n",
    "def get_mini_batch(image,target,ind,mbatch_size):\n",
    "    ind1,ind2 = ind*mbatch_size,(ind+1)*mbatch_size\n",
    "    mbatch_target  = [[elem[ind1:ind2] for elem in target[0]],\\\n",
    "                      [elem[ind1:ind2] for elem in target[1]],\\\n",
    "                      [elem[ind1:ind2] for elem in target[2]]]\n",
    "    mbatch_target += [elem[ind1:ind2] for elem in target[3:]]\n",
    "    return image[ind1:ind2], mbatch_target\n",
    "\n",
    "if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER): os.makedirs(TRAIN_CHECKPOINTS_FOLDER)\n",
    "os.system(f'mkdir -p {TRAIN_CHECKPOINTS_FOLDER}/model')\n",
    "os.system(f'mkdir -p {TRAIN_CHECKPOINTS_FOLDER}/mvars')\n",
    "\n",
    "def get_loss_wts():\n",
    "    return np.array([list(mat.numpy()) for mat in prior_loss_wts_matrix]).flatten()\n",
    "\n",
    "def update_prior():\n",
    "    _sum = loss_rate_matrix.sum() \n",
    "    x,y = loss_rate_matrix/ _sum\n",
    "    \n",
    "loss_rate_df = pd.DataFrame(loss_rate_matrix).T\n",
    "init_loss = 0\n",
    "epoch = -1\n",
    "learning_rates      = np.linspace(TRAIN_LR/10,TRAIN_LR,TRAIN_WARM_UP_EPOCHS*no_train_batch)\n",
    "#mtl_loss_wts_values = np.linspace(MTL_LOSS_WTS[2]/10,MTL_LOSS_WTS[2],TRAIN_WARM_UP_EPOCHS*no_train_batch)\n",
    "_frozen= TRAIN_FREEZE_EPOCH>0\n",
    "\n",
    "def np_one_hot():\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "\n",
    "OUTPUT_SIZES = TRAIN_INPUT_SIZE // np.array(YOLO_STRIDES)\n",
    "def decompress(x,shape=(16,14,14,3,85)):\n",
    "    x = zlib.decompress(x)\n",
    "    x = np.frombuffer(x,dtype=np.float32)\n",
    "    x = x.reshape(shape)\n",
    "    return x\n",
    "\n",
    "while 1:\n",
    "    epoch +=1\n",
    "    if os.path.exists('params.json'):\n",
    "        with open('params.json','r') as file:\n",
    "            param_dict = json.load(file)\n",
    "        globals().update(param_dict)\n",
    "    \n",
    "    if _frozen==True and epoch>=TRAIN_FREEZE_EPOCH:\n",
    "        for ind,layer in enumerate(yolo_model.layers):   \n",
    "            if 'block' in layer.name:\n",
    "                yolo_model.layers[ind].trainable = True\n",
    "            print(ind,layer.name,layer.trainable)\n",
    "            yolo_model.summary()\n",
    "            _frozen=False\n",
    "            \n",
    "    if epoch >= TRAIN_EPOCHS:\n",
    "        break\n",
    " \n",
    "    all_logs = [] ; sample_losses =[]\n",
    "    train_loss_dict=loss_dict_obj(); val_loss_dict = loss_dict_obj(); loss_dict={'Epoch' : epoch}\n",
    "    \n",
    "    batch_seg=[];batch_dst=[]\n",
    "    for batch_ind in tqdm(range(no_train_batch)):\n",
    "        \n",
    "        tstep = (epoch)*no_train_batch + batch_ind\n",
    "        if tstep < len(learning_rates):\n",
    "            optimizer.learning_rate = learning_rates[tstep]\n",
    "            #MTL_LOSS_WTS[2] = mtl_loss_wts_values[tstep]\n",
    "            \n",
    "        if TRAIN_INPUT_SIZE <TRAIN_SAVE_THR_SIZE :\n",
    "            path=TRAIN_DATA_SAVE_PATH+'batch_{}.npy'.format(str(batch_ind))\n",
    "            batch_data = np.load(path,allow_pickle=True)\n",
    "            batch_data[0] = np.float32(batch_data[0]/255.0)\n",
    "            for _i in range(NO_OF_GRID):\n",
    "                shape = (TRAIN_BATCH_SIZE,OUTPUT_SIZES[_i],OUTPUT_SIZES[_i],3,NUM_CLASS+5)\n",
    "                batch_data[1][_i][0] = decompress(batch_data[1][_i][0],shape)\n",
    "               \n",
    "        else:\n",
    "            batch_data=next(trainset)\n",
    "        \n",
    "        image_data, target = batch_data[0],list(batch_data[1])+[batch_dst,batch_seg]\n",
    "        train_loss,ret_det,ret_seg , norms_matrix= train_batch(image_data, target,frozen=_frozen)\n",
    "        del image_data, target, batch_data\n",
    "        \n",
    "        train_loss_dict.sum_update(train_loss)\n",
    "        all_logs+=[list(train_loss.values())]\n",
    "        if type(init_loss) == int and init_loss== 0:\n",
    "            init_loss = np.array([train_loss['iou_loss']+train_loss['conf_loss'],train_loss['prob_loss']])\n",
    "        else:\n",
    "            curr_loss = np.array([train_loss['iou_loss']+train_loss['conf_loss'],train_loss['prob_loss']])\n",
    "            \n",
    "            loss_rate_matrix = curr_loss / init_loss\n",
    "            loss_rate_df.loc[int(epoch*no_train_batch + batch_ind)] = loss_rate_matrix\n",
    "        \n",
    "        \n",
    "    train_loss_dict.divide(no_train_batch)\n",
    "    iou_val, conf_val, prob_val, total_val = 0, 0, 0, 0\n",
    "    batch_seg=[];batch_dst=[]\n",
    "    \n",
    "    for batch_ind in tqdm(range(no_val_batch)):\n",
    "        if TRAIN_INPUT_SIZE < TRAIN_SAVE_THR_SIZE:\n",
    "            path=TEST_DATA_SAVE_PATH+'batch_{}.npy'.format(str(batch_ind))\n",
    "            batch_data=np.load(path,allow_pickle=True)\n",
    "            batch_data[0] = np.float32(batch_data[0]/255.0)\n",
    "            for _i in range(NO_OF_GRID):\n",
    "                shape = (TEST_BATCH_SIZE,OUTPUT_SIZES[_i],OUTPUT_SIZES[_i],3,NUM_CLASS+5)\n",
    "                batch_data[1][_i][0] = decompress(batch_data[1][_i][0],shape)\n",
    "        else:\n",
    "            batch_data = next(testset)\n",
    "        \n",
    "        image_data, target = batch_data[0],list(batch_data[1])+[batch_dst,batch_seg]\n",
    "        val_loss = validate_step(image_data, target)\n",
    "        del image_data, target, batch_data\n",
    "        val_loss_dict.sum_update(val_loss)\n",
    "        \n",
    "    val_loss_dict.divide(no_val_batch)\n",
    "    loss_dict.update(train_loss_dict)\n",
    "    loss_dict.update(val_loss_dict)\n",
    "    print(loss_dict)\n",
    "    \n",
    "     \n",
    "    if epoch % TRAIN_SAVE_WEIGHTS_EVERY == 0:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER,'model', 'epoch_{}_val_det_loss_{}'.format(epoch,round(loss_dict['val_det_loss'],4)))\n",
    "        yolo_model.save_weights(save_directory+'/weights')\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER,'mvars', f'epoch_{epoch}.pkl')\n",
    "        with open(save_directory,'wb') as file:\n",
    "            pickle.dump([grads_conf_1,grads_conf_2],file)\n",
    "\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, f'loss_rate_matrix.csv')\n",
    "        loss_rate_df.to_csv(save_directory)\n",
    "\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>loss_dict['val_det_loss']:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, 'model')\n",
    "        yolo_model.save_weights(save_directory+'/weights')\n",
    "        best_val_loss = loss_dict['val_det_loss']\n",
    "\n",
    "    save_loss_logs(loss_dict,epoch)\n",
    "    save_std_logs(train_loss,all_logs,epoch)\n",
    "    #save_sample_losses(sample_losses,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa89dd2-c6c2-46fc-8596-5e3b02a6568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f479c-520c-4224-8048-37ac8b34afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(64*14*14*3*85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f3387-142d-40b8-baa8-3f5b25756573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo_model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fab47-c5bb-4982-b731-2f8ba8a850ee",
   "metadata": {},
   "source": [
    "alpha = 1.0\n",
    "rows = 224\n",
    "url          = 'https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/'\n",
    "model_name   = ('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_' +str(float(alpha)) + '_' + str(rows) + '.h5')\n",
    "weight_path  = url + model_name\n",
    "#weights_path = data_utils.get_file(model_name, weight_path, cache_subdir='models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
