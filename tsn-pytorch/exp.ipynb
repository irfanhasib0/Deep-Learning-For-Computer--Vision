{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c567d-8200-4fb4-a590-f650307bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "from dataset import TSNDataSet\n",
    "from models import TSN\n",
    "from transforms import *\n",
    "from opts import parser\n",
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    global args, best_prec1\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.dataset == 'ucf101':\n",
    "        num_class = 101\n",
    "    elif args.dataset == 'hmdb51':\n",
    "        num_class = 51\n",
    "    elif args.dataset == 'kinetics':\n",
    "        num_class = 400\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset '+args.dataset)\n",
    "\n",
    "    model = TSN(num_class, args.num_segments, args.modality,\n",
    "                base_model=args.arch,\n",
    "                consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn)\n",
    "\n",
    "    crop_size = model.crop_size\n",
    "    scale_size = model.scale_size\n",
    "    input_mean = model.input_mean\n",
    "    input_std = model.input_std\n",
    "    policies = model.get_optim_policies()\n",
    "    train_augmentation = model.get_augmentation()\n",
    "\n",
    "    model = torch.nn.DataParallel(model, device_ids=args.gpus).cuda()\n",
    "\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print((\"=> loading checkpoint '{}'\".format(args.resume)))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print((\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.evaluate, checkpoint['epoch'])))\n",
    "        else:\n",
    "            print((\"=> no checkpoint found at '{}'\".format(args.resume)))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Data loading code\n",
    "    if args.modality != 'RGBDiff':\n",
    "        normalize = GroupNormalize(input_mean, input_std)\n",
    "    else:\n",
    "        normalize = IdentityTransform()\n",
    "\n",
    "    if args.modality == 'RGB':\n",
    "        data_length = 1\n",
    "    elif args.modality in ['Flow', 'RGBDiff']:\n",
    "        data_length = 5\n",
    "        \n",
    "    transform = torchvision.transforms.Compose([\n",
    "                       train_augmentation,\n",
    "                       Stack(roll=args.arch == 'BNInception'),\n",
    "                       ToTorchFormatTensor(div=args.arch != 'BNInception'),\n",
    "                       normalize,\n",
    "                   ])\n",
    "    \n",
    "    dataset = TSNDataSet(\"\", args.train_list, num_segments=args.num_segments,\n",
    "                   new_length=data_length,\n",
    "                   modality=args.modality,\n",
    "                   image_tmpl=\"img_{:05d}.jpg\" if args.modality in [\"RGB\", \"RGBDiff\"] else args.flow_prefix+\"{}_{:05d}.jpg\",\n",
    "                   transform=transform)\n",
    "               \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        TSNDataSet(\"\", args.val_list, num_segments=args.num_segments,\n",
    "                   new_length=data_length,\n",
    "                   modality=args.modality,\n",
    "                   image_tmpl=\"img_{:05d}.jpg\" if args.modality in [\"RGB\", \"RGBDiff\"] else args.flow_prefix+\"{}_{:05d}.jpg\",\n",
    "                   random_shift=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       GroupScale(int(scale_size)),\n",
    "                       GroupCenterCrop(crop_size),\n",
    "                       Stack(roll=args.arch == 'BNInception'),\n",
    "                       ToTorchFormatTensor(div=args.arch != 'BNInception'),\n",
    "                       normalize,\n",
    "                   ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    if args.loss_type == 'nll':\n",
    "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss type\")\n",
    "\n",
    "    for group in policies:\n",
    "        print(('group: {} has {} params, lr_mult: {}, decay_mult: {}'.format(\n",
    "            group['name'], len(group['params']), group['lr_mult'], group['decay_mult'])))\n",
    "\n",
    "    optimizer = torch.optim.SGD(policies,\n",
    "                                args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, 0)\n",
    "        return\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch, args.lr_steps)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
    "            prec1 = validate(val_loader, model, criterion, (epoch + 1) * len(train_loader))\n",
    "\n",
    "            # remember best prec@1 and save checkpoint\n",
    "            is_best = prec1 > best_prec1\n",
    "            best_prec1 = max(prec1, best_prec1)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "            }, is_best)\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    if args.no_partialbn:\n",
    "        model.module.partialBN(False)\n",
    "    else:\n",
    "        model.module.partialBN(True)\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if args.clip_gradient is not None:\n",
    "            total_norm = clip_grad_norm(model.parameters(), args.clip_gradient)\n",
    "            if total_norm > args.clip_gradient:\n",
    "                print(\"clipping gradient: {} with coef {}\".format(total_norm, args.clip_gradient / total_norm))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print(('Epoch: [{0}][{1}/{2}], lr: {lr:.5f}\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5, lr=optimizer.param_groups[-1]['lr'])))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, iter, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print(('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5)))\n",
    "\n",
    "    print(('Testing Results: Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Loss {loss.avg:.5f}'\n",
    "          .format(top1=top1, top5=top5, loss=losses)))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    filename = '_'.join((args.snapshot_pref, args.modality.lower(), filename))\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        best_name = '_'.join((args.snapshot_pref, args.modality.lower(), 'model_best.pth.tar'))\n",
    "        shutil.copyfile(filename, best_name)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr_steps):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    decay = 0.1 ** (sum(epoch >= np.array(lr_steps)))\n",
    "    lr = args.lr * decay\n",
    "    decay = args.weight_decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr * param_group['lr_mult']\n",
    "        param_group['weight_decay'] = decay * param_group['decay_mult']\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5993316d-4b5e-4da8-bfa1-78e6dbcc78dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'normalize' from 'transforms' (/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/transforms.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNDataSet\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSN\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stack, ToTorchFormatTensor, normalize\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mParams\u001b[39;00m():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'normalize' from 'transforms' (/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/transforms.py)"
     ]
    }
   ],
   "source": [
    "#python main.py ucf101 RGB <ucf101_rgb_train_list> <ucf101_rgb_val_list> \\\n",
    "#   --arch BNInception --num_segments 3 \\\n",
    "#   --gd 20 --lr 0.001 --lr_steps 30 60 --epochs 80 \\\n",
    "#   -b 128 -j 8 --dropout 0.8 \\\n",
    "#   --snapshot_pref ucf101_bninception_ \n",
    "import torch\n",
    "import torchvision\n",
    "from dataset import TSNDataSet\n",
    "from models import TSN\n",
    "from transforms import Stack, ToTorchFormatTensor, normalize\n",
    "class Params():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'ucf101'\n",
    "        self.arch    = 'BNInception'\n",
    "        self.num_segments = 3\n",
    "        self.gd       = 20\n",
    "        self.lr       = 0.001\n",
    "        self.lr_steps = [30, 60]\n",
    "        self.epochs   = 80\n",
    "        self.b        = 128\n",
    "        self.j        = 8\n",
    "        self.dropout  = 0.8\n",
    "        self.snapshot_pref = 'ucf101_bninception_'\n",
    "        self.workers   = 2\n",
    "        self.train_list = '<ucf101_rgb_train_list>'\n",
    "        self.modality   = 'RGB'\n",
    "        self.consensus_type = 'avg'\n",
    "        self.no_partialbn   = False\n",
    "        self.gpus           = [torch.device('cuda')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4569ece-c733-474b-80e9-ad0e965aa0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()\n",
    "\n",
    "num_class = 101\n",
    "model = TSN(num_class, args.num_segments, args.modality,\n",
    "                base_model     = args.arch,\n",
    "                consensus_type = args.consensus_type, dropout = args.dropout, partial_bn = not args.no_partialbn)\n",
    "\n",
    "crop_size  = model.crop_size\n",
    "scale_size = model.scale_size\n",
    "input_mean = model.input_mean\n",
    "input_std  = model.input_std\n",
    "policies   = model.get_optim_policies()\n",
    "train_augmentation = model.get_augmentation()\n",
    "model              = torch.nn.DataParallel(model, device_ids=args.gpus).cuda()\n",
    "\n",
    "\n",
    "data_length = 1\n",
    "transform = torchvision.transforms.Compose([\n",
    "               train_augmentation,\n",
    "               Stack(roll=args.arch == 'BNInception'),\n",
    "               ToTorchFormatTensor(div=args.arch != 'BNInception'),\n",
    "               normalize,\n",
    "           ])\n",
    "\n",
    "dataset = TSNDataSet(\"\", args.train_list, num_segments=args.num_segments,\n",
    "           new_length = data_length,\n",
    "           modality   = args.modality,\n",
    "           image_tmpl = \"img_{:05d}.jpg\" if args.modality in [\"RGB\", \"RGBDiff\"] else args.flow_prefix+\"{}_{:05d}.jpg\",\n",
    "           transform  = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                           batch_size=args.batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798166c-8858-4a29-86d7-938483b3ff25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5efa5d3-d10d-4184-a4a0-f6302857c53c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (501243754.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python main.py ucf101 RGB <ucf101_rgb_train_list> <ucf101_rgb_val_list> \\\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python main.py ucf101 RGB <ucf101_rgb_train_list> <ucf101_rgb_val_list> \\\n",
    "   --arch BNInception --num_segments 3 \\\n",
    "   --gd 20 --lr 0.001 --lr_steps 30 60 --epochs 80 \\\n",
    "   -b 128 -j 8 --dropout 0.8 \\\n",
    "   --snapshot_pref ucf101_bninception_ \n",
    "\n",
    "weight_url = 'bn_inception-9f5701afb96c8044.pth'\n",
    "wts = torch.utils.model_zoo.load_url(weight_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ee1ae5-be9f-465f-9c75-54a03d594012",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd6fe83-060f-4016-aceb-c75f790acd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts['inception_4b_3x3_bn.bias'].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d8b4c7-7728-4a2c-8ad7-19dbe8421b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_model_zoo/bninception/bn_inception.yaml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "yaml.load('tf_model_zoo/bninception/bn_inception.yaml',Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9198a6b-4400-474f-b4e6-796989c46e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f846adc7-66ed-4e9b-976d-15e14248967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'tf_model_zoo',\n",
       " '__doc__': None,\n",
       " '__package__': 'tf_model_zoo',\n",
       " '__loader__': <_frozen_importlib_external._NamespaceLoader at 0x7f247eab9160>,\n",
       " '__spec__': ModuleSpec(name='tf_model_zoo', loader=<_frozen_importlib_external._NamespaceLoader object at 0x7f247eab9160>, submodule_search_locations=_NamespacePath(['/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/tf_model_zoo', '/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/tf_model_zoo'])),\n",
       " '__file__': None,\n",
       " '__path__': _NamespacePath(['/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/tf_model_zoo', '/home/irfan/Desktop/Code/Deep-Learning-For-Computer-Vision/tsn-pytorch/tf_model_zoo'])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model_zoo.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb8da9-150b-4c2b-83a6-ace2cec0e14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_38",
   "language": "python",
   "name": "python_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
